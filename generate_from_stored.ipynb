{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwTP4MYk0bYn"
   },
   "source": [
    "# Artificial Visual Imagination \n",
    "## Text to Image with BigGAN + CLIP + CMA-ES\n",
    "\n",
    "---\n",
    "\n",
    "BIGCLIP [j.mp/bigclip](https://j.mp/bigclip) by Eyal Gruss [@eyaler](https://twitter.com/eyaler) [eyalgruss.com](https://eyalgruss.com)\n",
    "\n",
    "\n",
    "Modified to run on nautilus.optiputer.net by robert.twomey@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generating from Saved Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from https://github.com/huggingface/pytorch-pretrained-BigGAN#usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, clear_output\n",
    "from PIL import Image\n",
    "# from IPython.display import Image\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "# from biggan\n",
    "import torch\n",
    "from pytorch_pretrained_biggan import (BigGAN, one_hot_from_names, truncated_noise_sample,\n",
    "                                       save_as_images, display_in_terminal)\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "model = BigGAN.from_pretrained('biggan-deep-512')\n",
    "print(\"loaded bigGAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save(out, name):\n",
    "#     with torch.no_grad():\n",
    "#         out = out.cpu().numpy()\n",
    "#     img = convert_to_images(out)[0]\n",
    "#     imageio.imwrite(name, np.asarray(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seeding\n",
    "np.random.RandomState(1)\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "\n",
    "# Prepare a input\n",
    "truncation = 1.0\n",
    "workbase = '/home/jovyan/'\n",
    "# noise_vector = np.loadtxt(workbase+'work/output_20210222_195143/noise_00008.txt')\n",
    "# class_vector = np.loadtxt(workbase+'work/output_20210222_195143/class_00008.txt')\n",
    "\n",
    "noise_vector = np.loadtxt(workbase+'work/visual-imagination/CLIP/noise_a room with good lighting.txt')\n",
    "class_vector = np.loadtxt(workbase+'work/visual-imagination/CLIP/class_a room with good lighting.txt')\n",
    "\n",
    "\n",
    "\n",
    "# noise_vector = noise_vectors\n",
    "# class_vector = class_vectors\n",
    "\n",
    "# expand dims\n",
    "noise_vector = np.expand_dims(noise_vector, axis=0)\n",
    "class_vector = np.expand_dims(class_vector, axis=0)\n",
    "\n",
    "# All in tensors\n",
    "noise_vector = torch.tensor(noise_vector, dtype=torch.float32)\n",
    "class_vector = torch.tensor(class_vector, dtype=torch.float32)\n",
    "\n",
    "print(noise_vector.shape, noise_vector.dtype, class_vector.shape, class_vector.dtype)\n",
    "\n",
    "# If you have a GPU, put everything on cuda\n",
    "noise_vector = noise_vector.to('cuda')\n",
    "noise_vector = noise_vector.clamp(-2*truncation, 2*truncation)\n",
    "class_vector = class_vector.to('cuda')\n",
    "class_vector = class_vector.softmax(dim=-1)\n",
    "model.to('cuda')\n",
    "\n",
    "# Generate an image\n",
    "with torch.no_grad():\n",
    "    output = model(noise_vector, class_vector, truncation)\n",
    "\n",
    "# If you have a GPU put back on CPU\n",
    "output = output.to('cpu')\n",
    "\n",
    "# # If you have a sixtel compatible terminal you can display the images in the terminal\n",
    "# # (see https://github.com/saitoha/libsixel for details)\n",
    "# # display_in_terminal(output)\n",
    "# save_as_images(output, \"output_%s\" % index)\n",
    "\n",
    "# display(Image(\"output_0.png\"))\n",
    "\n",
    "# # Save results as png images\n",
    "save_as_images(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "display(Image(\"output_0.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = 6\n",
    "\n",
    "# # random seeding\n",
    "# np.random.RandomState(1)\n",
    "# np.random.seed(1)\n",
    "# torch.manual_seed(1)\n",
    "\n",
    "\n",
    "# for index in range(50):\n",
    "    \n",
    "#     # Prepare a input\n",
    "#     truncation = 1.0\n",
    "#     noise_vectors = np.loadtxt('/home/jovyan/work/output_20210222_194102/class_00008.txt')\n",
    "#     class_vectors = np.loadtxt('/home/jovyan/work/output_20210222_194102/class_00009.txt')\n",
    "\n",
    "#     noise_vector = noise_vectors[index]\n",
    "#     class_vector = class_vectors[index]\n",
    "\n",
    "#     # expand dims\n",
    "#     noise_vector = np.expand_dims(noise_vector, axis=0)\n",
    "#     class_vector = np.expand_dims(class_vector, axis=0)\n",
    "\n",
    "#     # All in tensors\n",
    "#     noise_vector = torch.tensor(noise_vector, dtype=torch.float32)\n",
    "#     class_vector = torch.tensor(class_vector, dtype=torch.float32)\n",
    "\n",
    "#     print(noise_vector.shape, noise_vector.dtype, class_vector.shape, class_vector.dtype)\n",
    "\n",
    "#     # If you have a GPU, put everything on cuda\n",
    "#     noise_vector = noise_vector.to('cuda')\n",
    "#     noise_vector = noise_vector.clamp(-2*truncation, 2*truncation)\n",
    "#     class_vector = class_vector.to('cuda')\n",
    "#     class_vector = class_vector.softmax(dim=-1)\n",
    "#     model.to('cuda')\n",
    "\n",
    "#     # Generate an image\n",
    "#     with torch.no_grad():\n",
    "#         output = model(noise_vector, class_vector, truncation)\n",
    "\n",
    "#     # If you have a GPU put back on CPU\n",
    "#     output = output.to('cpu')\n",
    "\n",
    "#     # # If you have a sixtel compatible terminal you can display the images in the terminal\n",
    "#     # # (see https://github.com/saitoha/libsixel for details)\n",
    "#     # # display_in_terminal(output)\n",
    "#     save_as_images(output, \"output_%s\" % index)\n",
    "\n",
    "#     # # display(Image())\n",
    "\n",
    "#     # # Save results as png images\n",
    "#     # # save_as_images(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(50):\n",
    "#     print(\"Image %s:\" %i)\n",
    "#     display(Image('output_%s_0.png' % i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from huggingface\n",
    "# # # Prepare a input\n",
    "# # truncation = 0.4\n",
    "# class_vector = one_hot_from_names(['soap bubble', 'coffee', 'mushroom'], batch_size=3)\n",
    "# noise_vector = truncated_noise_sample(truncation=truncation, batch_size=3)\n",
    "# print(class_vector.shape, class_vector.dtype)\n",
    "# print(noise_vector.shape, class_vector.dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise_vec = np.loadtxt('/home/jovyan/work/output_20210221_175545/noise_00009.txt')\n",
    "# class_vec = np.loadtxt('/home/jovyan/work/output_20210221_175545/class_00009.txt')\n",
    "# # print(noise_vec, class_vec)\n",
    "\n",
    "# noise_vec = torch.tensor(noise_vec, dtype=torch.float32).cuda()\n",
    "# class_vec = torch.tensor(class_vec, dtype=torch.float32).cuda()\n",
    "\n",
    "# # vectors = torch.cat([noise_vector,class_vector], dim=1)\n",
    "# # print(vectors)\n",
    "# out, class_vector_norm = get_output(noise_vec, class_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd $outpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generate mp4\n",
    "# out = '%s.mp4'%prompt.replace(\" \", \"_\")\n",
    "# with open('list.txt','w') as f:\n",
    "#   for i in range(sample_num):\n",
    "#     f.write('file frame_%05d.jpg\\n'%i)\n",
    "#   for j in range(int(freeze_secs*fps)):\n",
    "#     f.write('file frame_%05d.jpg\\n'%i)\n",
    "# !ffmpeg -r $fps -f concat -safe 0 -i list.txt -c:v libx264 -pix_fmt yuv420p -profile:v baseline -movflags +faststart -r $fps $out -y\n",
    "\n",
    "# # rename jpg\n",
    "# frame = 'frame_%05d.jpg'%(sample_num-1)\n",
    "# jpg = '%s.jpg'%prompt.replace(\" \", \"_\")\n",
    "# !cp $frame $jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # move to datestamped path\n",
    "# import os, datetime\n",
    "# newdir = outpath[:-1]+\"_\"+datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "# !mv $outpath $newdir\n",
    "# !mkdir -p $outpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import display, FileLink, FileLinks\n",
    "\n",
    "# local_file = FileLink(out.replace('\"', \"\"), result_html_prefix=\"Click here to download: \")\n",
    "# # local_file = FileLinks(\".\", result_html_suffix=\"?download\")\n",
    "# display(local_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import HTML\n",
    "# local_file = out.replace('\"', \"\")\n",
    "# HTML(\"<a href=\\\"\"+local_file+\"\\\">download %s</a>\"%local_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Based on SIREN+CLIP Colabs by: [@advadnoun](https://twitter.com/advadnoun), [@norod78](https://twitter.com/norod78)\n",
    "\n",
    "Other CLIP notebooks: [OpenAI tutorial](https://colab.research.google.com/github/openai/clip/blob/master/Interacting_with_CLIP.ipynb), [SIREN by @advadnoun](https://colab.research.google.com/drive/1FoHdqoqKntliaQKnMoNs3yn5EALqWtvP), [SIREN by @norod78](https://colab.research.google.com/drive/1K1vfpTEvAmxW2rnhAaALRVyis8EiLOnD), [BigGAN by @advadnoun](https://colab.research.google.com/drive/1NCceX2mbiKOSlAd_o7IU7nA9UskKN5WR), [BigGAN by @eyaler](j.mp/bigclip), [BigGAN by @tg_bomze](https://colab.research.google.com/github/tg-bomze/collection-of-notebooks/blob/master/Text2Image_v2.ipynb), [BigGAN using big-sleep library by @lucidrains](https://colab.research.google.com/drive/1MEWKbm-driRNF8PrU7ogS5o3se-ePyPb), [BigGAN story hallucinator by @bonkerfield](https://colab.research.google.com/drive/1jF8pyZ7uaNYbk9ZiVdxTOajkp8kbmkLK), [StyleGAN2-ADA Anime by @nagolinc](https://colab.research.google.com/github/nagolinc/notebooks/blob/main/TADNE_and_CLIP.ipynb) [v2](https://colab.research.google.com/github/nagolinc/notebooks/blob/main/CLIP_%2B_TADNE_(pytorch)_v2.ipynb)\n",
    "\n",
    "Using the works:\n",
    "\n",
    "https://github.com/openai/CLIP\n",
    "\n",
    "https://tfhub.dev/deepmind/biggan-deep-512\n",
    "\n",
    "https://github.com/huggingface/pytorch-pretrained-BigGAN\n",
    "\n",
    "http://www.aiartonline.com/design-2019/eyal-gruss (WanderGAN)\n",
    "\n",
    "For a curated list of more online generative tools see: [j.mp/generativetools](https://j.mp/generativetools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "WanderCLIP.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
