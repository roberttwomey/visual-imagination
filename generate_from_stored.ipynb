{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwTP4MYk0bYn"
   },
   "source": [
    "# Artificial Visual Imagination \n",
    "## Text to Image with BigGAN + CLIP + CMA-ES\n",
    "\n",
    "---\n",
    "\n",
    "BIGCLIP [j.mp/bigclip](https://j.mp/bigclip) by Eyal Gruss [@eyaler](https://twitter.com/eyaler) [eyalgruss.com](https://eyalgruss.com)\n",
    "\n",
    "\n",
    "Modified to run on nautilus.optiputer.net by robert.twomey@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generating from Saved Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from https://github.com/huggingface/pytorch-pretrained-BigGAN#usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded bigGAN\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import HTML, clear_output\n",
    "from PIL import Image\n",
    "from IPython.display import Image as JupImage\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "# from biggan\n",
    "import torch\n",
    "from pytorch_pretrained_biggan import (BigGAN, one_hot_from_names, truncated_noise_sample,\n",
    "                                       save_as_images, display_in_terminal)\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "model = BigGAN.from_pretrained('biggan-deep-512')\n",
    "print(\"loaded bigGAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save(out, name):\n",
    "#     with torch.no_grad():\n",
    "#         out = out.cpu().numpy()\n",
    "#     img = convert_to_images(out)[0]\n",
    "#     imageio.imwrite(name, np.asarray(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image\n",
    "# display(Image(\"output_0.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate from a set of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = 6\n",
    "\n",
    "# # random seeding\n",
    "# np.random.RandomState(1)\n",
    "# np.random.seed(1)\n",
    "# torch.manual_seed(1)\n",
    "\n",
    "\n",
    "# for index in range(50):\n",
    "    \n",
    "#     # Prepare a input\n",
    "#     truncation = 1.0\n",
    "#     noise_vectors = np.loadtxt('/home/jovyan/work/output_20210222_194102/class_00008.txt')\n",
    "#     class_vectors = np.loadtxt('/home/jovyan/work/output_20210222_194102/class_00009.txt')\n",
    "\n",
    "#     noise_vector = noise_vectors[index]\n",
    "#     class_vector = class_vectors[index]\n",
    "\n",
    "#     # expand dims\n",
    "#     noise_vector = np.expand_dims(noise_vector, axis=0)\n",
    "#     class_vector = np.expand_dims(class_vector, axis=0)\n",
    "\n",
    "#     # All in tensors\n",
    "#     noise_vector = torch.tensor(noise_vector, dtype=torch.float32)\n",
    "#     class_vector = torch.tensor(class_vector, dtype=torch.float32)\n",
    "\n",
    "#     print(noise_vector.shape, noise_vector.dtype, class_vector.shape, class_vector.dtype)\n",
    "\n",
    "#     # If you have a GPU, put everything on cuda\n",
    "#     noise_vector = noise_vector.to('cuda')\n",
    "#     noise_vector = noise_vector.clamp(-2*truncation, 2*truncation)\n",
    "#     class_vector = class_vector.to('cuda')\n",
    "#     class_vector = class_vector.softmax(dim=-1)\n",
    "#     model.to('cuda')\n",
    "\n",
    "#     # Generate an image\n",
    "#     with torch.no_grad():\n",
    "#         output = model(noise_vector, class_vector, truncation)\n",
    "\n",
    "#     # If you have a GPU put back on CPU\n",
    "#     output = output.to('cpu')\n",
    "\n",
    "#     # # If you have a sixtel compatible terminal you can display the images in the terminal\n",
    "#     # # (see https://github.com/saitoha/libsixel for details)\n",
    "#     # # display_in_terminal(output)\n",
    "#     save_as_images(output, \"output_%s\" % index)\n",
    "\n",
    "#     # # display(Image())\n",
    "\n",
    "#     # # Save results as png images\n",
    "#     # # save_as_images(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(50):\n",
    "#     print(\"Image %s:\" %i)\n",
    "#     display(Image('output_%s_0.png' % i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from huggingface\n",
    "# # # Prepare a input\n",
    "# # truncation = 0.4\n",
    "# class_vector = one_hot_from_names(['soap bubble', 'coffee', 'mushroom'], batch_size=3)\n",
    "# noise_vector = truncated_noise_sample(truncation=truncation, batch_size=3)\n",
    "# print(class_vector.shape, class_vector.dtype)\n",
    "# print(noise_vector.shape, class_vector.dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise_vec = np.loadtxt('/home/jovyan/work/output_20210221_175545/noise_00009.txt')\n",
    "# class_vec = np.loadtxt('/home/jovyan/work/output_20210221_175545/class_00009.txt')\n",
    "# # print(noise_vec, class_vec)\n",
    "\n",
    "# noise_vec = torch.tensor(noise_vec, dtype=torch.float32).cuda()\n",
    "# class_vec = torch.tensor(class_vec, dtype=torch.float32).cuda()\n",
    "\n",
    "# # vectors = torch.cat([noise_vector,class_vector], dim=1)\n",
    "# # print(vectors)\n",
    "# out, class_vector_norm = get_output(noise_vec, class_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Latent+Class Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import asarray\n",
    "from numpy import vstack\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from numpy import arccos\n",
    "from numpy import clip\n",
    "from numpy import dot\n",
    "from numpy import sin\n",
    "from numpy import linspace\n",
    "from numpy.linalg import norm\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# from\n",
    "# https://discuss.pytorch.org/t/help-regarding-slerp-function-for-generative-model-sampling/32475/4\n",
    "\n",
    "# spherical linear interpolation (slerp)\n",
    "def slerp(val, low, high):\n",
    "    omega = arccos(clip(dot(low/norm(low), high/norm(high)), -1, 1))\n",
    "    so = sin(omega)\n",
    "    if so == 0:\n",
    "        # L'Hopital's rule/LERP\n",
    "        return (1.0-val) * low + val * high\n",
    "    return sin((1.0-val)*omega) / so * low + sin(val*omega) / so * high\n",
    " \n",
    "# uniform interpolation between two points in latent space\n",
    "def interpolate_points(p1, p2, n_steps=10):\n",
    "    # interpolate ratios between the points\n",
    "    ratios = np.linspace(0, 1, num=n_steps)\n",
    "    # linear interpolate vectors\n",
    "    vectors = list()\n",
    "    for ratio in ratios:\n",
    "        v = slerp(ratio, p1, p2)\n",
    "        vectors.append(v)\n",
    "    return np.asarray(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolate between a set of vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.RandomState(1)\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Prepare a input\n",
    "truncation = 1.0\n",
    "resultsbase = '/home/jovyan/work/results/'\n",
    "workbase = '/home/jovyan/work/'\n",
    "interpbase = '/home/jovyan/work/interpolation'\n",
    "\n",
    "# sculptures: \n",
    "\n",
    "# class_filenames = [\n",
    "# \"work/visual-imagination/CLIP/class_sculpture television buddha.txt\",\n",
    "# \"work/visual-imagination/CLIP/class_a buddha sculpture with television in the grass.txt\",\n",
    "# \"work/visual-imagination/CLIP/class_television buddha sculpture with grass.txt\",\n",
    "# \"work/visual-imagination/CLIP/class_old television in grass with buddha sculpture by pacific ocean.txt\",\n",
    "# \"work/visual-imagination/CLIP/class_old television in long grass with buddha sculpture by pacific ocean.txt\"\n",
    "# ]\n",
    "\n",
    "# noise_filenames = [\n",
    "# \"work/visual-imagination/CLIP/noise_sculpture television buddha.txt\",\n",
    "# \"work/visual-imagination/CLIP/noise_a buddha sculpture with television in the grass.txt\",\n",
    "# \"work/visual-imagination/CLIP/noise_television buddha sculpture with grass.txt\",\n",
    "# \"work/visual-imagination/CLIP/noise_old television in grass with buddha sculpture by pacific ocean.txt\",\n",
    "# \"work/visual-imagination/CLIP/noise_old television in long grass with buddha sculpture by pacific ocean.txt\"\n",
    "# ]\n",
    "\n",
    "prompts = [\n",
    "    'a photo of wild tarragon',\n",
    "    'a drawing of wild tarragon, a tasteless plant',\n",
    "    'a painting of farm hands, a kind of laborer',\n",
    "    'a painting of a farmer’s hands',\n",
    "    'a self-portrait of Artemisia Gentileschi, artist',\n",
    "    'artemisia Gentileschi is a dragon',\n",
    "    'a painting of Artemisia Gentileschi as a dragon',\n",
    "    'a photo of the dragon Artemisia Gentileschi',\n",
    "    'a portrait of artist as dragon',\n",
    "    'a drawing of a dragon',\n",
    "    'a painting of uprooted rhizome as a dragon',\n",
    "    'a sketch of a rhizome, uprooted',\n",
    "    'an image of a plant rising',\n",
    "    'a drawing of plant roots and mycorrhizal fungi',\n",
    "    'an image of growing wiser',\n",
    "    'a painting of wise plants',\n",
    "    'a drawing of plant wisdom',\n",
    "    'a photo of a plant hiding',\n",
    "    'a drawing of hiding from elders',\n",
    "    'a painting of Susanna and the Elders',\n",
    "    'an image of creeps',\n",
    "    'a painting of gazing creeps',\n",
    "    'a painting of groping creeps',\n",
    "    'a painting of invasive elders',\n",
    "    'a photo of perverse hope',\n",
    "    'a painting of your hatred',\n",
    "    'a drawing of killing a mosquito',\n",
    "    'a painting of a mosquito, a kind of corpse',\n",
    "    'a drawing of malaria',\n",
    "    'a sketch of salted fields',\n",
    "    'a photo of dancers',\n",
    "    'a painting of dancers in a field',\n",
    "    'an image of your spit',\n",
    "    'a photo of standing too close',\n",
    "    'a painting of someone standing too close',\n",
    "    'a drawing of an oak sapling',\n",
    "    'a painting of an oak in an empty field',\n",
    "    'a photo of growing',\n",
    "    'an image of growing wilder',\n",
    "    'a painting of growing stronger',\n",
    "    'a photo of a hand holding high',\n",
    "    'a painting of a hand holding the head of Holofernes',\n",
    "    'a painting of the head of Holofernes',\n",
    "    'a drawing of a head, blood-rooted',\n",
    "    'an image of a bloody root',\n",
    "    'a painting of autumn gold',\n",
    "    'a photo of a golden gown',\n",
    "    'an image of a mouth tasting',\n",
    "    'a sketch of a mouth',\n",
    "    'a drawing of taste',\n",
    "    'a painting of the taste of nothing',\n",
    "    'a photograph of being invisible',\n",
    "    'a drawing of your renown',\n",
    "    'a painting of a renowned artist',\n",
    "    'a portrait of the artist',\n",
    "    'a self-portrait of Artemisia Gentileschi as tarragon'\n",
    "]\n",
    "\n",
    "safe_prompts = [prompt.replace(' ', '_') for prompt in prompts]\n",
    "\n",
    "# print(safe_prompts)\n",
    "\n",
    "def get_class_file(path, prompt):\n",
    "    result = glob.glob(path+'%s_*_class.txt'%prompt)\n",
    "    return(result)\n",
    "\n",
    "def get_noise_file(path, prompt):\n",
    "    result = glob.glob(path+'%s_*_noise.txt'%prompt)\n",
    "    return(result)\n",
    "\n",
    "# print(get_class_file(workbase, safe_prompts[0]))\n",
    "# print(get_noise_file(workbase, safe_prompts[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/jovyan/work/results/a_photo_of_wild_tarragon_20210227_140023_class.txt', '/home/jovyan/work/results/a_drawing_of_wild_tarragon,_a_tasteless_plant_20210227_140504_class.txt', '/home/jovyan/work/results/a_painting_of_farm_hands,_a_kind_of_laborer_20210227_140945_class.txt', '/home/jovyan/work/results/a_painting_of_a_farmer’s_hands_20210227_141432_class.txt', '/home/jovyan/work/results/a_self-portrait_of_Artemisia_Gentileschi,_artist_20210227_141920_class.txt', '/home/jovyan/work/results/artemisia_Gentileschi_is_a_dragon_20210227_142403_class.txt', '/home/jovyan/work/results/a_painting_of_Artemisia_Gentileschi_as_a_dragon_20210227_142843_class.txt', '/home/jovyan/work/results/a_photo_of_the_dragon_Artemisia_Gentileschi_20210227_143328_class.txt', '/home/jovyan/work/results/a_portrait_of_artist_as_dragon_20210227_143807_class.txt', '/home/jovyan/work/results/a_drawing_of_a_dragon_20210227_151124_class.txt', '/home/jovyan/work/results/a_painting_of_uprooted_rhizome_as_a_dragon_20210227_151602_class.txt', '/home/jovyan/work/results/a_sketch_of_a_rhizome,_uprooted_20210227_152044_class.txt', '/home/jovyan/work/results/an_image_of_a_plant_rising_20210227_152522_class.txt', '/home/jovyan/work/results/a_drawing_of_plant_roots_and_mycorrhizal_fungi_20210227_153013_class.txt', '/home/jovyan/work/results/an_image_of_growing_wiser_20210227_153452_class.txt', '/home/jovyan/work/results/a_painting_of_wise_plants_20210227_153934_class.txt', '/home/jovyan/work/results/a_drawing_of_plant_wisdom_20210227_154413_class.txt', '/home/jovyan/work/results/a_photo_of_a_plant_hiding_20210227_154853_class.txt', '/home/jovyan/work/results/a_drawing_of_hiding_from_elders_20210227_155335_class.txt', '/home/jovyan/work/results/a_painting_of_Susanna_and_the_Elders_20210227_155817_class.txt', '/home/jovyan/work/results/an_image_of_creeps_20210227_160259_class.txt', '/home/jovyan/work/results/a_painting_of_gazing_creeps_20210227_160742_class.txt', '/home/jovyan/work/results/a_painting_of_groping_creeps_20210227_161224_class.txt', '/home/jovyan/work/results/a_painting_of_invasive_elders_20210227_161710_class.txt', '/home/jovyan/work/results/a_photo_of_perverse_hope_20210227_162153_class.txt', '/home/jovyan/work/results/a_painting_of_your_hatred_20210227_162634_class.txt', '/home/jovyan/work/results/a_drawing_of_killing_a_mosquito_20210227_163118_class.txt', '/home/jovyan/work/results/a_painting_of_a_mosquito,_a_kind_of_corpse_20210227_163556_class.txt', '/home/jovyan/work/results/a_drawing_of_malaria_20210227_164042_class.txt', '/home/jovyan/work/results/a_sketch_of_salted_fields_20210227_164518_class.txt', '/home/jovyan/work/results/a_photo_of_dancers_20210227_164956_class.txt', '/home/jovyan/work/results/a_painting_of_dancers_in_a_field_20210227_165433_class.txt', '/home/jovyan/work/results/an_image_of_your_spit_20210227_165912_class.txt', '/home/jovyan/work/results/a_photo_of_standing_too_close_20210227_170354_class.txt', '/home/jovyan/work/results/a_painting_of_someone_standing_too_close_20210227_170843_class.txt', '/home/jovyan/work/results/a_drawing_of_an_oak_sapling_20210227_171323_class.txt', '/home/jovyan/work/results/a_painting_of_an_oak_in_an_empty_field_20210227_171802_class.txt', '/home/jovyan/work/results/a_photo_of_growing_20210227_172243_class.txt', '/home/jovyan/work/results/an_image_of_growing_wilder_20210227_172720_class.txt', '/home/jovyan/work/results/a_painting_of_growing_stronger_20210227_173203_class.txt', '/home/jovyan/work/results/a_photo_of_a_hand_holding_high_20210227_173639_class.txt', '/home/jovyan/work/results/a_painting_of_a_hand_holding_the_head_of_Holofernes_20210227_174123_class.txt', '/home/jovyan/work/results/a_painting_of_the_head_of_Holofernes_20210227_174558_class.txt', '/home/jovyan/work/results/a_drawing_of_a_head,_blood-rooted_20210227_175042_class.txt', '/home/jovyan/work/results/an_image_of_a_bloody_root_20210227_175522_class.txt', '/home/jovyan/work/results/a_painting_of_autumn_gold_20210227_180002_class.txt', '/home/jovyan/work/results/a_photo_of_a_golden_gown_20210227_180437_class.txt', '/home/jovyan/work/results/an_image_of_a_mouth_tasting_20210227_180914_class.txt', '/home/jovyan/work/results/a_sketch_of_a_mouth_20210227_181350_class.txt', '/home/jovyan/work/results/a_drawing_of_taste_20210227_181830_class.txt', '/home/jovyan/work/results/a_painting_of_the_taste_of_nothing_20210227_182308_class.txt', '/home/jovyan/work/results/a_photograph_of_being_invisible_20210227_182747_class.txt', '/home/jovyan/work/results/a_drawing_of_your_renown_20210227_183228_class.txt', '/home/jovyan/work/results/a_painting_of_a_renowned_artist_20210227_183710_class.txt', '/home/jovyan/work/results/a_portrait_of_the_artist_20210227_184153_class.txt', '/home/jovyan/work/results/a_self-portrait_of_Artemisia_Gentileschi_as_tarragon_20210227_184626_class.txt'] ['/home/jovyan/work/results/a_photo_of_wild_tarragon_20210227_140023_noise.txt', '/home/jovyan/work/results/a_drawing_of_wild_tarragon,_a_tasteless_plant_20210227_140504_noise.txt', '/home/jovyan/work/results/a_painting_of_farm_hands,_a_kind_of_laborer_20210227_140945_noise.txt', '/home/jovyan/work/results/a_painting_of_a_farmer’s_hands_20210227_141432_noise.txt', '/home/jovyan/work/results/a_self-portrait_of_Artemisia_Gentileschi,_artist_20210227_141920_noise.txt', '/home/jovyan/work/results/artemisia_Gentileschi_is_a_dragon_20210227_142403_noise.txt', '/home/jovyan/work/results/a_painting_of_Artemisia_Gentileschi_as_a_dragon_20210227_142843_noise.txt', '/home/jovyan/work/results/a_photo_of_the_dragon_Artemisia_Gentileschi_20210227_143328_noise.txt', '/home/jovyan/work/results/a_portrait_of_artist_as_dragon_20210227_143807_noise.txt', '/home/jovyan/work/results/a_drawing_of_a_dragon_20210227_151124_noise.txt', '/home/jovyan/work/results/a_painting_of_uprooted_rhizome_as_a_dragon_20210227_151602_noise.txt', '/home/jovyan/work/results/a_sketch_of_a_rhizome,_uprooted_20210227_152044_noise.txt', '/home/jovyan/work/results/an_image_of_a_plant_rising_20210227_152522_noise.txt', '/home/jovyan/work/results/a_drawing_of_plant_roots_and_mycorrhizal_fungi_20210227_153013_noise.txt', '/home/jovyan/work/results/an_image_of_growing_wiser_20210227_153452_noise.txt', '/home/jovyan/work/results/a_painting_of_wise_plants_20210227_153934_noise.txt', '/home/jovyan/work/results/a_drawing_of_plant_wisdom_20210227_154413_noise.txt', '/home/jovyan/work/results/a_photo_of_a_plant_hiding_20210227_154853_noise.txt', '/home/jovyan/work/results/a_drawing_of_hiding_from_elders_20210227_155335_noise.txt', '/home/jovyan/work/results/a_painting_of_Susanna_and_the_Elders_20210227_155817_noise.txt', '/home/jovyan/work/results/an_image_of_creeps_20210227_160259_noise.txt', '/home/jovyan/work/results/a_painting_of_gazing_creeps_20210227_160742_noise.txt', '/home/jovyan/work/results/a_painting_of_groping_creeps_20210227_161224_noise.txt', '/home/jovyan/work/results/a_painting_of_invasive_elders_20210227_161710_noise.txt', '/home/jovyan/work/results/a_photo_of_perverse_hope_20210227_162153_noise.txt', '/home/jovyan/work/results/a_painting_of_your_hatred_20210227_162634_noise.txt', '/home/jovyan/work/results/a_drawing_of_killing_a_mosquito_20210227_163118_noise.txt', '/home/jovyan/work/results/a_painting_of_a_mosquito,_a_kind_of_corpse_20210227_163556_noise.txt', '/home/jovyan/work/results/a_drawing_of_malaria_20210227_164042_noise.txt', '/home/jovyan/work/results/a_sketch_of_salted_fields_20210227_164518_noise.txt', '/home/jovyan/work/results/a_photo_of_dancers_20210227_164956_noise.txt', '/home/jovyan/work/results/a_painting_of_dancers_in_a_field_20210227_165433_noise.txt', '/home/jovyan/work/results/an_image_of_your_spit_20210227_165912_noise.txt', '/home/jovyan/work/results/a_photo_of_standing_too_close_20210227_170354_noise.txt', '/home/jovyan/work/results/a_painting_of_someone_standing_too_close_20210227_170843_noise.txt', '/home/jovyan/work/results/a_drawing_of_an_oak_sapling_20210227_171323_noise.txt', '/home/jovyan/work/results/a_painting_of_an_oak_in_an_empty_field_20210227_171802_noise.txt', '/home/jovyan/work/results/a_photo_of_growing_20210227_172243_noise.txt', '/home/jovyan/work/results/an_image_of_growing_wilder_20210227_172720_noise.txt', '/home/jovyan/work/results/a_painting_of_growing_stronger_20210227_173203_noise.txt', '/home/jovyan/work/results/a_photo_of_a_hand_holding_high_20210227_173639_noise.txt', '/home/jovyan/work/results/a_painting_of_a_hand_holding_the_head_of_Holofernes_20210227_174123_noise.txt', '/home/jovyan/work/results/a_painting_of_the_head_of_Holofernes_20210227_174558_noise.txt', '/home/jovyan/work/results/a_drawing_of_a_head,_blood-rooted_20210227_175042_noise.txt', '/home/jovyan/work/results/an_image_of_a_bloody_root_20210227_175522_noise.txt', '/home/jovyan/work/results/a_painting_of_autumn_gold_20210227_180002_noise.txt', '/home/jovyan/work/results/a_photo_of_a_golden_gown_20210227_180437_noise.txt', '/home/jovyan/work/results/an_image_of_a_mouth_tasting_20210227_180914_noise.txt', '/home/jovyan/work/results/a_sketch_of_a_mouth_20210227_181350_noise.txt', '/home/jovyan/work/results/a_drawing_of_taste_20210227_181830_noise.txt', '/home/jovyan/work/results/a_painting_of_the_taste_of_nothing_20210227_182308_noise.txt', '/home/jovyan/work/results/a_photograph_of_being_invisible_20210227_182747_noise.txt', '/home/jovyan/work/results/a_drawing_of_your_renown_20210227_183228_noise.txt', '/home/jovyan/work/results/a_painting_of_a_renowned_artist_20210227_183710_noise.txt', '/home/jovyan/work/results/a_portrait_of_the_artist_20210227_184153_noise.txt', '/home/jovyan/work/results/a_self-portrait_of_Artemisia_Gentileschi_as_tarragon_20210227_184626_noise.txt']\n"
     ]
    }
   ],
   "source": [
    "class_filenames = [get_class_file(resultsbase, prompt)[0] for prompt in safe_prompts]\n",
    "noise_filenames = [get_noise_file(resultsbase, prompt)[0] for prompt in safe_prompts]\n",
    "\n",
    "# print(class_filenames, noise_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 200 #300\n",
    "len_hold = 30\n",
    "\n",
    "class_inputs = [np.loadtxt(filename) for filename in class_filenames]\n",
    "noise_inputs = [np.loadtxt(filename) for filename in noise_filenames]\n",
    "\n",
    "# print(class_inputs, noise_inputs)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i in range(len(class_inputs)):\n",
    "    \n",
    "    # interpolate\n",
    "    noises = interpolate_points(noise_inputs[i], noise_inputs[(i+1)%len(class_inputs)], num_steps)\n",
    "    classes = interpolate_points(class_inputs[i], class_inputs[(i+1)%len(class_inputs)], num_steps)\n",
    "\n",
    "    for j in range(num_steps):\n",
    "\n",
    "        # expand dims\n",
    "        noise_vector = np.expand_dims(noises[j], axis=0)\n",
    "        class_vector = np.expand_dims(classes[j], axis=0)\n",
    "\n",
    "        # convert to tensors\n",
    "        noise_vector = torch.tensor(noise_vector, dtype=torch.float32)\n",
    "        class_vector = torch.tensor(class_vector, dtype=torch.float32)\n",
    "    \n",
    "        # If you have a GPU, put everything on cuda\n",
    "        noise_vector = noise_vector.to('cuda')\n",
    "        noise_vector = noise_vector.clamp(-2*truncation, 2*truncation)\n",
    "        class_vector = class_vector.to('cuda')\n",
    "        class_vector = class_vector.softmax(dim=-1)\n",
    "        model.to('cuda')\n",
    "\n",
    "        # Generate an image\n",
    "        with torch.no_grad():\n",
    "            output = model(noise_vector, class_vector, truncation)\n",
    "\n",
    "        # If you have a GPU put back on CPU\n",
    "        output = output.to('cpu')\n",
    "\n",
    "        # # If you have a sixtel compatible terminal you can display the images in the terminal\n",
    "        # # (see https://github.com/saitoha/libsixel for details)\n",
    "    \n",
    "        # \"hold\" on the first frame for fixed time\n",
    "        if j == 0:\n",
    "            for k in range(len_hold-1):\n",
    "                save_as_images(output, interpbase+\"/output_%05d\" % count)\n",
    "                count = count + 1\n",
    "    #     clear_output()\n",
    "    #     display(JupImage(\"output_%05d_0.png\" % i))\n",
    "    \n",
    "        save_as_images(output, interpbase+\"/output_%05d\" % count)\n",
    "        count = count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd $outpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/work/visual-imagination'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12824\n"
     ]
    }
   ],
   "source": [
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg -r 45 -f concat -safe 0 -i list.txt -c:v libx264 -pix_fmt yuv420p -profile:v baseline -movflags +faststart -r 45 tarragon_interp45.mp4 -y\n"
     ]
    }
   ],
   "source": [
    "# generate mp4\n",
    "fps = 45\n",
    "out = 'tarragon_interp%s.mp4'%fps\n",
    "with open('list.txt','w') as f:\n",
    "  for i in range(count):\n",
    "    f.write('file %sinterpolation/output_%05d_0.png\\n'%(workbase, i))\n",
    "# !ffmpeg -r $fps -f concat -safe 0 -i list.txt -c:v libx264 -pix_fmt yuv420p -profile:v baseline -movflags +faststart -r $fps $out -y\n",
    "!echo ffmpeg -r $fps -f concat -safe 0 -i list.txt -c:v libx264 -pix_fmt yuv420p -profile:v baseline -movflags +faststart -r $fps $out -y\n",
    "\n",
    "# # rename jpg\n",
    "# frame = 'frame_%05d.jpg'%(sample_num-1)\n",
    "# jpg = '%s.jpg'%prompt.replace(\" \", \"_\")\n",
    "# !cp $frame $jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # move to datestamped path\n",
    "# import os, datetime\n",
    "# newdir = outpath[:-1]+\"_\"+datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "# !mv $outpath $newdir\n",
    "# !mkdir -p $outpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import display, FileLink, FileLinks\n",
    "\n",
    "# local_file = FileLink(out.replace('\"', \"\"), result_html_prefix=\"Click here to download: \")\n",
    "# # local_file = FileLinks(\".\", result_html_suffix=\"?download\")\n",
    "# display(local_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import HTML\n",
    "# local_file = out.replace('\"', \"\")\n",
    "# HTML(\"<a href=\\\"\"+local_file+\"\\\">download %s</a>\"%local_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Based on SIREN+CLIP Colabs by: [@advadnoun](https://twitter.com/advadnoun), [@norod78](https://twitter.com/norod78)\n",
    "\n",
    "Other CLIP notebooks: [OpenAI tutorial](https://colab.research.google.com/github/openai/clip/blob/master/Interacting_with_CLIP.ipynb), [SIREN by @advadnoun](https://colab.research.google.com/drive/1FoHdqoqKntliaQKnMoNs3yn5EALqWtvP), [SIREN by @norod78](https://colab.research.google.com/drive/1K1vfpTEvAmxW2rnhAaALRVyis8EiLOnD), [BigGAN by @advadnoun](https://colab.research.google.com/drive/1NCceX2mbiKOSlAd_o7IU7nA9UskKN5WR), [BigGAN by @eyaler](j.mp/bigclip), [BigGAN by @tg_bomze](https://colab.research.google.com/github/tg-bomze/collection-of-notebooks/blob/master/Text2Image_v2.ipynb), [BigGAN using big-sleep library by @lucidrains](https://colab.research.google.com/drive/1MEWKbm-driRNF8PrU7ogS5o3se-ePyPb), [BigGAN story hallucinator by @bonkerfield](https://colab.research.google.com/drive/1jF8pyZ7uaNYbk9ZiVdxTOajkp8kbmkLK), [StyleGAN2-ADA Anime by @nagolinc](https://colab.research.google.com/github/nagolinc/notebooks/blob/main/TADNE_and_CLIP.ipynb) [v2](https://colab.research.google.com/github/nagolinc/notebooks/blob/main/CLIP_%2B_TADNE_(pytorch)_v2.ipynb)\n",
    "\n",
    "Using the works:\n",
    "\n",
    "https://github.com/openai/CLIP\n",
    "\n",
    "https://tfhub.dev/deepmind/biggan-deep-512\n",
    "\n",
    "https://github.com/huggingface/pytorch-pretrained-BigGAN\n",
    "\n",
    "http://www.aiartonline.com/design-2019/eyal-gruss (WanderGAN)\n",
    "\n",
    "For a curated list of more online generative tools see: [j.mp/generativetools](https://j.mp/generativetools)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leftovers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex2. Interpolating between two vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.RandomState(1)\n",
    "# np.random.seed(1)\n",
    "# torch.manual_seed(1)\n",
    "\n",
    "# num_steps = 500\n",
    "\n",
    "# # Prepare a input\n",
    "# truncation = 1.0\n",
    "# workbase = '/home/jovyan/'\n",
    "\n",
    "# # sculptures: \n",
    "\n",
    "\n",
    "# # work/visual-imagination/CLIP/class_sculpture television buddha.txt\n",
    "# # work/visual-imagination/CLIP/class_a buddha sculpture with television in the grass.txt\n",
    "# # work/visual-imagination/CLIP/class_television buddha sculpture with grass.txt\n",
    "# # work/visual-imagination/CLIP/class_old television in grass with buddha sculpture by pacific ocean.txt\n",
    "# # work/visual-imagination/CLIP/class_old television in long grass with buddha sculpture by pacific ocean.txt\n",
    "\n",
    "\n",
    "# noise1 = np.loadtxt(workbase+'work/output_20210222_195143/noise_00002.txt')\n",
    "# class1 = np.loadtxt(workbase+'work/output_20210222_195143/class_00002.txt')\n",
    "\n",
    "# noise2 = np.loadtxt(workbase+'work/output_20210222_195143/noise_00008.txt')\n",
    "# class2 = np.loadtxt(workbase+'work/output_20210222_195143/class_00008.txt')\n",
    "\n",
    "# # noise_vector = np.loadtxt(workbase+'work/visual-imagination/CLIP/noise_a room with good lighting.txt')\n",
    "# # class_vector = np.loadtxt(workbase+'work/visual-imagination/CLIP/class_a room with good lighting.txt')\n",
    "\n",
    "# # interpolate\n",
    "# noises = interpolate_points(noise1, noise2, num_steps)\n",
    "# classes = interpolate_points(class1, class2, num_steps)\n",
    "\n",
    "# # expand dims (only necessary for single vector)\n",
    "\n",
    "# for i in range(num_steps):\n",
    "    \n",
    "#     # expand dims\n",
    "#     noise_vector = np.expand_dims(noises[i], axis=0)\n",
    "#     class_vector = np.expand_dims(classes[i], axis=0)\n",
    "\n",
    "#     # convert to tensors\n",
    "#     noise_vector = torch.tensor(noise_vector, dtype=torch.float32)\n",
    "#     class_vector = torch.tensor(class_vector, dtype=torch.float32)\n",
    "\n",
    "#     print(noise_vector.shape, noise_vector.dtype, class_vector.shape, class_vector.dtype)\n",
    "\n",
    "#     # If you have a GPU, put everything on cuda\n",
    "#     noise_vector = noise_vector.to('cuda')\n",
    "#     noise_vector = noise_vector.clamp(-2*truncation, 2*truncation)\n",
    "#     class_vector = class_vector.to('cuda')\n",
    "#     class_vector = class_vector.softmax(dim=-1)\n",
    "#     model.to('cuda')\n",
    "\n",
    "#     # Generate an image\n",
    "#     with torch.no_grad():\n",
    "#         output = model(noise_vector, class_vector, truncation)\n",
    "\n",
    "#     # If you have a GPU put back on CPU\n",
    "#     output = output.to('cpu')\n",
    "\n",
    "#     # # If you have a sixtel compatible terminal you can display the images in the terminal\n",
    "#     # # (see https://github.com/saitoha/libsixel for details)\n",
    "#     # # display_in_terminal(output)\n",
    "#     save_as_images(output, workbase+\"work/output_%05d\" % i)\n",
    "# #     clear_output()\n",
    "# #     display(JupImage(\"output_%05d_0.png\" % i))\n",
    "#     i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex.1: Generate from a single stored noise/class vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # random seeding\n",
    "# np.random.RandomState(1)\n",
    "# np.random.seed(1)\n",
    "# torch.manual_seed(1)\n",
    "\n",
    "\n",
    "# # Prepare a input\n",
    "# truncation = 1.0\n",
    "# workbase = '/home/jovyan/'\n",
    "# noise_vector = np.loadtxt(workbase+'work/output_20210222_195143/noise_00008.txt')\n",
    "# class_vector = np.loadtxt(workbase+'work/output_20210222_195143/class_00008.txt')\n",
    "\n",
    "# # noise_vector = np.loadtxt(workbase+'work/visual-imagination/CLIP/noise_a room with good lighting.txt')\n",
    "# # class_vector = np.loadtxt(workbase+'work/visual-imagination/CLIP/class_a room with good lighting.txt')\n",
    "\n",
    "\n",
    "\n",
    "# # noise_vector = noise_vectors\n",
    "# # class_vector = class_vectors\n",
    "\n",
    "# # expand dims\n",
    "# noise_vector = np.expand_dims(noise_vector, axis=0)\n",
    "# class_vector = np.expand_dims(class_vector, axis=0)\n",
    "\n",
    "# # All in tensors\n",
    "# noise_vector = torch.tensor(noise_vector, dtype=torch.float32)\n",
    "# class_vector = torch.tensor(class_vector, dtype=torch.float32)\n",
    "\n",
    "# print(noise_vector.shape, noise_vector.dtype, class_vector.shape, class_vector.dtype)\n",
    "\n",
    "# # If you have a GPU, put everything on cuda\n",
    "# noise_vector = noise_vector.to('cuda')\n",
    "# noise_vector = noise_vector.clamp(-2*truncation, 2*truncation)\n",
    "# class_vector = class_vector.to('cuda')\n",
    "# class_vector = class_vector.softmax(dim=-1)\n",
    "# model.to('cuda')\n",
    "\n",
    "# # Generate an image\n",
    "# with torch.no_grad():\n",
    "#     output = model(noise_vector, class_vector, truncation)\n",
    "\n",
    "# # If you have a GPU put back on CPU\n",
    "# output = output.to('cpu')\n",
    "\n",
    "# # # If you have a sixtel compatible terminal you can display the images in the terminal\n",
    "# # # (see https://github.com/saitoha/libsixel for details)\n",
    "# # # display_in_terminal(output)\n",
    "# # save_as_images(output, \"output_%s\" % index)\n",
    "\n",
    "# # display(Image(\"output_0.png\"))\n",
    "\n",
    "# # # Save results as png images\n",
    "# save_as_images(output)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "WanderCLIP.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
