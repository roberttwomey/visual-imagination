{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwTP4MYk0bYn"
   },
   "source": [
    "# Artificial Visual Imagination \n",
    "## Text to Image with BigGAN + CLIP + CMA-ES\n",
    "\n",
    "---\n",
    "\n",
    "BIGCLIP [j.mp/bigclip](https://j.mp/bigclip) by Eyal Gruss [@eyaler](https://twitter.com/eyaler) [eyalgruss.com](https://eyalgruss.com)\n",
    "\n",
    "\n",
    "Modified to run on nautilus.optiputer.net by robert.twomey@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generating from Saved Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from https://github.com/huggingface/pytorch-pretrained-BigGAN#usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded bigGAN\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import HTML, clear_output\n",
    "from PIL import Image\n",
    "from IPython.display import Image as JupImage\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "# from biggan\n",
    "import torch\n",
    "from pytorch_pretrained_biggan import (BigGAN, one_hot_from_names, truncated_noise_sample,\n",
    "                                       save_as_images, display_in_terminal)\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "model = BigGAN.from_pretrained('biggan-deep-512')\n",
    "print(\"loaded bigGAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save(out, name):\n",
    "#     with torch.no_grad():\n",
    "#         out = out.cpu().numpy()\n",
    "#     img = convert_to_images(out)[0]\n",
    "#     imageio.imwrite(name, np.asarray(img))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Generate from a single stored noise/class vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # random seeding\n",
    "# np.random.RandomState(1)\n",
    "# np.random.seed(1)\n",
    "# torch.manual_seed(1)\n",
    "\n",
    "\n",
    "# # Prepare a input\n",
    "# truncation = 1.0\n",
    "# workbase = '/home/jovyan/'\n",
    "# noise_vector = np.loadtxt(workbase+'work/output_20210222_195143/noise_00008.txt')\n",
    "# class_vector = np.loadtxt(workbase+'work/output_20210222_195143/class_00008.txt')\n",
    "\n",
    "# # noise_vector = np.loadtxt(workbase+'work/visual-imagination/CLIP/noise_a room with good lighting.txt')\n",
    "# # class_vector = np.loadtxt(workbase+'work/visual-imagination/CLIP/class_a room with good lighting.txt')\n",
    "\n",
    "\n",
    "\n",
    "# # noise_vector = noise_vectors\n",
    "# # class_vector = class_vectors\n",
    "\n",
    "# # expand dims\n",
    "# noise_vector = np.expand_dims(noise_vector, axis=0)\n",
    "# class_vector = np.expand_dims(class_vector, axis=0)\n",
    "\n",
    "# # All in tensors\n",
    "# noise_vector = torch.tensor(noise_vector, dtype=torch.float32)\n",
    "# class_vector = torch.tensor(class_vector, dtype=torch.float32)\n",
    "\n",
    "# print(noise_vector.shape, noise_vector.dtype, class_vector.shape, class_vector.dtype)\n",
    "\n",
    "# # If you have a GPU, put everything on cuda\n",
    "# noise_vector = noise_vector.to('cuda')\n",
    "# noise_vector = noise_vector.clamp(-2*truncation, 2*truncation)\n",
    "# class_vector = class_vector.to('cuda')\n",
    "# class_vector = class_vector.softmax(dim=-1)\n",
    "# model.to('cuda')\n",
    "\n",
    "# # Generate an image\n",
    "# with torch.no_grad():\n",
    "#     output = model(noise_vector, class_vector, truncation)\n",
    "\n",
    "# # If you have a GPU put back on CPU\n",
    "# output = output.to('cpu')\n",
    "\n",
    "# # # If you have a sixtel compatible terminal you can display the images in the terminal\n",
    "# # # (see https://github.com/saitoha/libsixel for details)\n",
    "# # # display_in_terminal(output)\n",
    "# # save_as_images(output, \"output_%s\" % index)\n",
    "\n",
    "# # display(Image(\"output_0.png\"))\n",
    "\n",
    "# # # Save results as png images\n",
    "# save_as_images(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image\n",
    "# display(Image(\"output_0.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate from a set of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = 6\n",
    "\n",
    "# # random seeding\n",
    "# np.random.RandomState(1)\n",
    "# np.random.seed(1)\n",
    "# torch.manual_seed(1)\n",
    "\n",
    "\n",
    "# for index in range(50):\n",
    "    \n",
    "#     # Prepare a input\n",
    "#     truncation = 1.0\n",
    "#     noise_vectors = np.loadtxt('/home/jovyan/work/output_20210222_194102/class_00008.txt')\n",
    "#     class_vectors = np.loadtxt('/home/jovyan/work/output_20210222_194102/class_00009.txt')\n",
    "\n",
    "#     noise_vector = noise_vectors[index]\n",
    "#     class_vector = class_vectors[index]\n",
    "\n",
    "#     # expand dims\n",
    "#     noise_vector = np.expand_dims(noise_vector, axis=0)\n",
    "#     class_vector = np.expand_dims(class_vector, axis=0)\n",
    "\n",
    "#     # All in tensors\n",
    "#     noise_vector = torch.tensor(noise_vector, dtype=torch.float32)\n",
    "#     class_vector = torch.tensor(class_vector, dtype=torch.float32)\n",
    "\n",
    "#     print(noise_vector.shape, noise_vector.dtype, class_vector.shape, class_vector.dtype)\n",
    "\n",
    "#     # If you have a GPU, put everything on cuda\n",
    "#     noise_vector = noise_vector.to('cuda')\n",
    "#     noise_vector = noise_vector.clamp(-2*truncation, 2*truncation)\n",
    "#     class_vector = class_vector.to('cuda')\n",
    "#     class_vector = class_vector.softmax(dim=-1)\n",
    "#     model.to('cuda')\n",
    "\n",
    "#     # Generate an image\n",
    "#     with torch.no_grad():\n",
    "#         output = model(noise_vector, class_vector, truncation)\n",
    "\n",
    "#     # If you have a GPU put back on CPU\n",
    "#     output = output.to('cpu')\n",
    "\n",
    "#     # # If you have a sixtel compatible terminal you can display the images in the terminal\n",
    "#     # # (see https://github.com/saitoha/libsixel for details)\n",
    "#     # # display_in_terminal(output)\n",
    "#     save_as_images(output, \"output_%s\" % index)\n",
    "\n",
    "#     # # display(Image())\n",
    "\n",
    "#     # # Save results as png images\n",
    "#     # # save_as_images(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(50):\n",
    "#     print(\"Image %s:\" %i)\n",
    "#     display(Image('output_%s_0.png' % i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from huggingface\n",
    "# # # Prepare a input\n",
    "# # truncation = 0.4\n",
    "# class_vector = one_hot_from_names(['soap bubble', 'coffee', 'mushroom'], batch_size=3)\n",
    "# noise_vector = truncated_noise_sample(truncation=truncation, batch_size=3)\n",
    "# print(class_vector.shape, class_vector.dtype)\n",
    "# print(noise_vector.shape, class_vector.dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise_vec = np.loadtxt('/home/jovyan/work/output_20210221_175545/noise_00009.txt')\n",
    "# class_vec = np.loadtxt('/home/jovyan/work/output_20210221_175545/class_00009.txt')\n",
    "# # print(noise_vec, class_vec)\n",
    "\n",
    "# noise_vec = torch.tensor(noise_vec, dtype=torch.float32).cuda()\n",
    "# class_vec = torch.tensor(class_vec, dtype=torch.float32).cuda()\n",
    "\n",
    "# # vectors = torch.cat([noise_vector,class_vector], dim=1)\n",
    "# # print(vectors)\n",
    "# out, class_vector_norm = get_output(noise_vec, class_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Latent+Class Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import asarray\n",
    "from numpy import vstack\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from numpy import arccos\n",
    "from numpy import clip\n",
    "from numpy import dot\n",
    "from numpy import sin\n",
    "from numpy import linspace\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# from\n",
    "# https://discuss.pytorch.org/t/help-regarding-slerp-function-for-generative-model-sampling/32475/4\n",
    "\n",
    "# spherical linear interpolation (slerp)\n",
    "def slerp(val, low, high):\n",
    "    omega = arccos(clip(dot(low/norm(low), high/norm(high)), -1, 1))\n",
    "    so = sin(omega)\n",
    "    if so == 0:\n",
    "        # L'Hopital's rule/LERP\n",
    "        return (1.0-val) * low + val * high\n",
    "    return sin((1.0-val)*omega) / so * low + sin(val*omega) / so * high\n",
    " \n",
    "# uniform interpolation between two points in latent space\n",
    "def interpolate_points(p1, p2, n_steps=10):\n",
    "    # interpolate ratios between the points\n",
    "    ratios = np.linspace(0, 1, num=n_steps)\n",
    "    # linear interpolate vectors\n",
    "    vectors = list()\n",
    "    for ratio in ratios:\n",
    "        v = slerp(ratio, p1, p2)\n",
    "        vectors.append(v)\n",
    "    return np.asarray(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n",
      "torch.Size([1, 128]) torch.float32 torch.Size([1, 1000]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "np.random.RandomState(1)\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "num_steps = 500\n",
    "\n",
    "# Prepare a input\n",
    "truncation = 1.0\n",
    "workbase = '/home/jovyan/'\n",
    "\n",
    "# sculptures: \n",
    "#     work/visual-imagination/CLIP/class_sculpture television buddha.txt\n",
    "#     work/visual-imagination/CLIP/class_television buddha sculpture with grass.txt\n",
    "\n",
    "\n",
    "noise1 = np.loadtxt(workbase+'work/output_20210222_195143/noise_00002.txt')\n",
    "class1 = np.loadtxt(workbase+'work/output_20210222_195143/class_00002.txt')\n",
    "\n",
    "noise2 = np.loadtxt(workbase+'work/output_20210222_195143/noise_00008.txt')\n",
    "class2 = np.loadtxt(workbase+'work/output_20210222_195143/class_00008.txt')\n",
    "\n",
    "# noise_vector = np.loadtxt(workbase+'work/visual-imagination/CLIP/noise_a room with good lighting.txt')\n",
    "# class_vector = np.loadtxt(workbase+'work/visual-imagination/CLIP/class_a room with good lighting.txt')\n",
    "\n",
    "# interpolate\n",
    "noises = interpolate_points(noise1, noise2, num_steps)\n",
    "classes = interpolate_points(class1, class2, num_steps)\n",
    "\n",
    "# expand dims (only necessary for single vector)\n",
    "\n",
    "\n",
    "for i in range(num_steps):\n",
    "    \n",
    "    # expand dims\n",
    "    noise_vector = np.expand_dims(noises[i], axis=0)\n",
    "    class_vector = np.expand_dims(classes[i], axis=0)\n",
    "\n",
    "    # convert to tensors\n",
    "    noise_vector = torch.tensor(noise_vector, dtype=torch.float32)\n",
    "    class_vector = torch.tensor(class_vector, dtype=torch.float32)\n",
    "\n",
    "    print(noise_vector.shape, noise_vector.dtype, class_vector.shape, class_vector.dtype)\n",
    "\n",
    "    # If you have a GPU, put everything on cuda\n",
    "    noise_vector = noise_vector.to('cuda')\n",
    "    noise_vector = noise_vector.clamp(-2*truncation, 2*truncation)\n",
    "    class_vector = class_vector.to('cuda')\n",
    "    class_vector = class_vector.softmax(dim=-1)\n",
    "    model.to('cuda')\n",
    "\n",
    "    # Generate an image\n",
    "    with torch.no_grad():\n",
    "        output = model(noise_vector, class_vector, truncation)\n",
    "\n",
    "    # If you have a GPU put back on CPU\n",
    "    output = output.to('cpu')\n",
    "\n",
    "    # # If you have a sixtel compatible terminal you can display the images in the terminal\n",
    "    # # (see https://github.com/saitoha/libsixel for details)\n",
    "    # # display_in_terminal(output)\n",
    "    save_as_images(output, workbase+\"work/output_%05d\" % i)\n",
    "#     clear_output()\n",
    "#     display(JupImage(\"output_%05d_0.png\" % i))\n",
    "    i+=1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd $outpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
      "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
      "  libavutil      55. 78.100 / 55. 78.100\n",
      "  libavcodec     57.107.100 / 57.107.100\n",
      "  libavformat    57. 83.100 / 57. 83.100\n",
      "  libavdevice    57. 10.100 / 57. 10.100\n",
      "  libavfilter     6.107.100 /  6.107.100\n",
      "  libavresample   3.  7.  0 /  3.  7.  0\n",
      "  libswscale      4.  8.100 /  4.  8.100\n",
      "  libswresample   2.  9.100 /  2.  9.100\n",
      "  libpostproc    54.  7.100 / 54.  7.100\n",
      "Input #0, concat, from 'list.txt':\n",
      "  Duration: N/A, start: 0.000000, bitrate: N/A\n",
      "    Stream #0:0: Video: png, rgb24(pc), 512x512, 25 tbr, 25 tbn, 25 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[0;35m[concat @ 0x55f22f98faa0] \u001b[0m\u001b[0;33mDTS -230575710986777 < 0 out of order\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[1;36m[libx264 @ 0x55f22f9a93e0] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
      "\u001b[1;36m[libx264 @ 0x55f22f9a93e0] \u001b[0mprofile Constrained Baseline, level 2.2\n",
      "\u001b[1;36m[libx264 @ 0x55f22f9a93e0] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=0 ref=3 deblock=1:0:0 analyse=0x1:0x111 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=0 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=16 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=0 weightp=0 keyint=250 keyint_min=5 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'test.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf57.83.100\n",
      "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 512x512, q=-1--1, 5 fps, 10240 tbn, 5 tbc\n",
      "    Metadata:\n",
      "      encoder         : Lavc57.107.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping0 bitrate=N/A speed=   0x    \n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping80 bitrate=   0.1kbits/s speed=4.79x    \n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[0;33mDTS -230575710986777, next:40000 st:0 invalid dropping\n",
      "\u001b[0m\u001b[0;33mPTS -230575710986777, next:40000 invalid dropping st:0\n",
      "\u001b[0m\u001b[1;35m[mp4 @ 0x55f22f9a7e20] \u001b[0mStarting second pass: moving the moov atom to the beginning of the file\n",
      "frame=  100 fps= 71 q=-1.0 Lsize=     697kB time=00:00:19.80 bitrate= 288.6kbits/s speed=14.1x    \n",
      "video:696kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.171257%\n",
      "\u001b[1;36m[libx264 @ 0x55f22f9a93e0] \u001b[0mframe I:2     Avg QP:18.01  size: 17440\n",
      "\u001b[1;36m[libx264 @ 0x55f22f9a93e0] \u001b[0mframe P:98    Avg QP:18.32  size:  6913\n",
      "\u001b[1;36m[libx264 @ 0x55f22f9a93e0] \u001b[0mmb I  I16..4: 31.7%  0.0% 68.3%\n",
      "\u001b[1;36m[libx264 @ 0x55f22f9a93e0] \u001b[0mmb P  I16..4:  5.2%  0.0%  3.9%  P16..4: 55.1% 21.4%  7.2%  0.0%  0.0%    skip: 7.2%\n",
      "\u001b[1;36m[libx264 @ 0x55f22f9a93e0] \u001b[0mcoded y,uvDC,uvAC intra: 62.4% 78.0% 35.7% inter: 29.7% 52.5% 1.5%\n",
      "\u001b[1;36m[libx264 @ 0x55f22f9a93e0] \u001b[0mi16 v,h,dc,p: 19% 24%  4% 53%\n",
      "\u001b[1;36m[libx264 @ 0x55f22f9a93e0] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 24% 22% 18%  6%  7%  7%  7%  5%  4%\n",
      "\u001b[1;36m[libx264 @ 0x55f22f9a93e0] \u001b[0mi8c dc,h,v,p: 33% 30% 22% 14%\n",
      "\u001b[1;36m[libx264 @ 0x55f22f9a93e0] \u001b[0mref P L0: 86.7%  9.4%  4.0%\n",
      "\u001b[1;36m[libx264 @ 0x55f22f9a93e0] \u001b[0mkb/s:284.93\n"
     ]
    }
   ],
   "source": [
    "# generate mp4\n",
    "fps = 5\n",
    "out = 'test.mp4'\n",
    "with open('list.txt','w') as f:\n",
    "  for i in range(num_steps):\n",
    "    f.write('file output_%02d_0.png\\n'%i)\n",
    "# !ffmpeg -r $fps -f concat -safe 0 -i list.txt -c:v libx264 -pix_fmt yuv420p -profile:v baseline -movflags +faststart -r $fps $out -y\n",
    "!ffmpeg -r $fps -f concat -safe 0 -i list.txt -c:v libx264 -pix_fmt yuv420p -profile:v baseline -movflags +faststart -r $fps $out -y\n",
    "\n",
    "# # rename jpg\n",
    "# frame = 'frame_%05d.jpg'%(sample_num-1)\n",
    "# jpg = '%s.jpg'%prompt.replace(\" \", \"_\")\n",
    "# !cp $frame $jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # move to datestamped path\n",
    "# import os, datetime\n",
    "# newdir = outpath[:-1]+\"_\"+datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "# !mv $outpath $newdir\n",
    "# !mkdir -p $outpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import display, FileLink, FileLinks\n",
    "\n",
    "# local_file = FileLink(out.replace('\"', \"\"), result_html_prefix=\"Click here to download: \")\n",
    "# # local_file = FileLinks(\".\", result_html_suffix=\"?download\")\n",
    "# display(local_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import HTML\n",
    "# local_file = out.replace('\"', \"\")\n",
    "# HTML(\"<a href=\\\"\"+local_file+\"\\\">download %s</a>\"%local_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Based on SIREN+CLIP Colabs by: [@advadnoun](https://twitter.com/advadnoun), [@norod78](https://twitter.com/norod78)\n",
    "\n",
    "Other CLIP notebooks: [OpenAI tutorial](https://colab.research.google.com/github/openai/clip/blob/master/Interacting_with_CLIP.ipynb), [SIREN by @advadnoun](https://colab.research.google.com/drive/1FoHdqoqKntliaQKnMoNs3yn5EALqWtvP), [SIREN by @norod78](https://colab.research.google.com/drive/1K1vfpTEvAmxW2rnhAaALRVyis8EiLOnD), [BigGAN by @advadnoun](https://colab.research.google.com/drive/1NCceX2mbiKOSlAd_o7IU7nA9UskKN5WR), [BigGAN by @eyaler](j.mp/bigclip), [BigGAN by @tg_bomze](https://colab.research.google.com/github/tg-bomze/collection-of-notebooks/blob/master/Text2Image_v2.ipynb), [BigGAN using big-sleep library by @lucidrains](https://colab.research.google.com/drive/1MEWKbm-driRNF8PrU7ogS5o3se-ePyPb), [BigGAN story hallucinator by @bonkerfield](https://colab.research.google.com/drive/1jF8pyZ7uaNYbk9ZiVdxTOajkp8kbmkLK), [StyleGAN2-ADA Anime by @nagolinc](https://colab.research.google.com/github/nagolinc/notebooks/blob/main/TADNE_and_CLIP.ipynb) [v2](https://colab.research.google.com/github/nagolinc/notebooks/blob/main/CLIP_%2B_TADNE_(pytorch)_v2.ipynb)\n",
    "\n",
    "Using the works:\n",
    "\n",
    "https://github.com/openai/CLIP\n",
    "\n",
    "https://tfhub.dev/deepmind/biggan-deep-512\n",
    "\n",
    "https://github.com/huggingface/pytorch-pretrained-BigGAN\n",
    "\n",
    "http://www.aiartonline.com/design-2019/eyal-gruss (WanderGAN)\n",
    "\n",
    "For a curated list of more online generative tools see: [j.mp/generativetools](https://j.mp/generativetools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "WanderCLIP.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
