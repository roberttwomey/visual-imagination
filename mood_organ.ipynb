{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwTP4MYk0bYn"
   },
   "source": [
    "# POM21 Text to Image Synthesis with Stored Vectors\n",
    "BigGAN + CLIP + CMA-ES.\n",
    "\n",
    "## NEWER VERSION\n",
    "\n",
    "Based on [j.mp/wanderclip](https://j.mp/wanderclip) by Eyal Gruss [@eyaler](https://twitter.com/eyaler) [eyalgruss.com](https://eyalgruss.com)\n",
    "\n",
    "Modified to run on nautilus.optiputer.net/z8 by robert.twomey@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Here, Then Run All\n",
    "\n",
    "Results show up in `/work/results/` in the file browser at left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f7f060c5d50>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/ipython-autotime/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f7f060f1650>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/ipython-autotime/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f7f060f1f10>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/ipython-autotime/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f7f060f1950>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/ipython-autotime/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f7f060f1690>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/ipython-autotime/\u001b[0m\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement ipython-autotime (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for ipython-autotime\u001b[0m\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autotime'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6321d6309b5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install ipython-autotime'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'autotime'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2315\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-64>\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magics/extension.py\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodule_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUsageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Missing module name.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'already loaded'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/extensions.py\u001b[0m in \u001b[0;36mload_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule_str\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprepended_to_syspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                         print((\"Loading extensions from {dir} is deprecated. \"\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'autotime'"
     ]
    }
   ],
   "source": [
    "!pip install ipython-autotime\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "EWmKTmvBg7z5"
   },
   "outputs": [],
   "source": [
    "# prompts_performance = [\n",
    "#     \"a euglena in a petri dish\",\n",
    "#     \"a ginger cat\"\n",
    "#     \"a viola provides the potential for communication\"\n",
    "#     \"the potentiality of the virtual space\"\n",
    "#     \"a human living with a machine\"\n",
    "#     \"decomposing matter with the roots of a plant\"\n",
    "#     \"a euglena seen through a microscope\"\n",
    "#     \"a unexpected surprise\"\n",
    "#     \"the decomposition of an artificial intelligence\"\n",
    "#     \"the extraction of thought from human writers\"\n",
    "# #     \"setting our machines loose into rich nourishing nature\"\n",
    "# ]\n",
    "\n",
    "prompts = [\"a seed, a plant's basic unit, remains ever in potentia\"\n",
    "]\n",
    "# prompts = [\n",
    "#     # 001 - POM Intro\n",
    "#     \"an elegant machine that learns to generate artificial images\",\n",
    "#     \"the sublime experience of an iceberg\",\n",
    "#     \"ice is a vastness of possibilities\",\n",
    "#     \"the vastness of possibilities of water is not a spatial vastness\",\n",
    "#     # 002\n",
    "#     \"a drawing of an elegant machine\",\n",
    "#     \"a machine that learns to make images\",\n",
    "#     \"a drawing of a machine that learns to make images\",\n",
    "#     # 003\n",
    "#     \"eighteenth century painting of humans encountering nature\",\n",
    "#     \"a person encountering nature\",\n",
    "#     \"a vastness of spatial dimensions\",\n",
    "#     \"a network\",\n",
    "#     \"a network of vast spatial dimensions\",\n",
    "#     \"a space of unlimited possibilities that the network must explore\"\n",
    "# ]\n",
    "\n",
    "# prompts += [\n",
    "#     # prompt 1\n",
    "#     \"a mushroom is the aerial manifestation of a larger infestation\",\n",
    "#     \"a mushrooms above ground growth is the result of a set of instructions\",\n",
    "#     \"growing mushrooms in the fire-stricken forests of LA\",\n",
    "#     \"growing mushrooms in the forests is a way to uncover their potential\"    \n",
    "#     \"a seed, a plant's basic unit, remains ever in potentia\",\n",
    "#     \"they make us have arms and not wings\", \n",
    "#     \"the fire-stricken forests of LA\",\n",
    "#     \"the fruiting body of a larger organism\"\n",
    "# ]\n",
    "\n",
    "# prompts += [\n",
    "#     ## prompt 2\n",
    "#     \"a family of robotic seals\",\n",
    "#     \"nursing homes in japan\",\n",
    "#     \"to help the elderly cope\", \n",
    "#     \"the after effects of the Tsunami\",\n",
    "#     \"the children laugh and smile\",\n",
    "#     \"their homes washed away\",\n",
    "#     \"watching the news on television\",\n",
    "#     \"spoke through a microphone\",\n",
    "#     \"the robotic seals danced\",\n",
    "#     \"the glow of a television screen\",\n",
    "# ]\n",
    "\n",
    "\n",
    "# prompts += [\n",
    "#     # prompt 3\n",
    "#     \"an xray of the first silicon chip\",\n",
    "#     \"the dover demonstration chip\",\n",
    "#     \"a picture of his arthritic hands\",\n",
    "#     \"a piece of wire to connect two silicon squares\",\n",
    "#     \"smaller and smaller computer chips\",\n",
    "#     \"the kilby diode\",\n",
    "#     \"a silicon mold of a friends hands\",\n",
    "#     \"in these containers, we care for machines\",    \n",
    "# ]\n",
    "\n",
    "# prompts += [\n",
    "#     #prompt 4\n",
    "#     \"the first computing devices were powered by steam engines\",\n",
    "#     \"fueled with the burning of fossilized coal\",\n",
    "#     \"the bones of sparse data structures\",\n",
    "#     \"the slow demise of our geological resources\",\n",
    "#     \"extracting lithium\",\n",
    "#     \"battery technology\",\n",
    "#     \"computing devices can be charged without being plugged in\",\n",
    "#     \"key contributor to climate change\",\n",
    "#     \"we are powered by imagination\",\n",
    "#     \"the machines we use to think\",\n",
    "#     \"the machines that are destroying the planet\"\n",
    "# ]\n",
    "\n",
    "# prompts += [\n",
    "#     #prompt 5\n",
    "#     \"a painting of pygmalion\",\n",
    "#     \"a sculptor who fell in love with his own sculpture\",\n",
    "#     \"everyone who saw her would fall in love with her\",\n",
    "#     \"beautiful reflections of our digital twinse\",\n",
    "#     \"a statue of a woman\",\n",
    "#     \"a living breathing woman\",\n",
    "#     \"our digital twins, artificial intelligence\",\n",
    "#     \"a projection of our deepest fears\"\n",
    "# ]\n",
    "\n",
    "\n",
    "# seeding/iteration\n",
    "seed = 10 #15#11#128#10 #255 #255#1#5#9#3\n",
    "iterations = 40#50#100#40\n",
    "terminal_iterations = iterations\n",
    "\n",
    "# file paths\n",
    "outpath = \"/home/jovyan/work/outputs_pom_seed_{}/\".format(seed)\n",
    "storedpath = \"/home/jovyan/work/process/stored_outputs_pom_seed_{}_{}it/\".format(seed,iterations)\n",
    "resultspath = \"/home/jovyan/work/results/results_pom_seed_{}_{}it/\".format(seed, iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 -f https://download.pytorch.org/whl/torch_stable.html ftfy regex\n",
    "!pip install pytorch-pretrained-biggan\n",
    "!pip install nltk\n",
    "!pip install cma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports to start session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models:\n",
    "\n",
    "- BigGAN Deep 512\n",
    "- CLIP OpenAI\n",
    "- Wordnet\n",
    "- CMA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "1SDpkkK7cU1y"
   },
   "outputs": [],
   "source": [
    "from pytorch_pretrained_biggan import BigGAN\n",
    "last_gen_model = 'biggan-deep-512'\n",
    "biggan_model = BigGAN.from_pretrained(last_gen_model).cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "last_clip_model = 'ViT-B/32'\n",
    "perceptor, preprocess = clip.load(last_clip_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cma\n",
    "from cma.sigma_adaptation import CMAAdaptSigmaCSA, CMAAdaptSigmaTPA\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", cma.evolution_strategy.InjectionWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For **prompt** OpenAI suggest to use the template \"A photo of a X.\" or \"A photo of a X, a type of Y.\" [[paper]](https://cdn.openai.com/papers/Learning_Transferable_Visual_Models_From_Natural_Language_Supervision.pdf)\n",
    "2. For **initial_class** you can either use free text or select a special option from the drop-down list.\n",
    "3. Free text and 'From prompt' might fail to find an appropriate ImageNet class.\n",
    "4. **seed**=0 means no seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "AOWzPLrBbdxW"
   },
   "outputs": [],
   "source": [
    "# prompt is set above\n",
    "gen_model = 'biggan-deep' #@param ['biggan-deep', 'sigmoid']\n",
    "size = '512' #@param [512, 256, 128] \n",
    "color = True #@param {type:'boolean'}\n",
    "initial_class = 'Random mix' #@param ['From prompt', 'Random class', 'Random Dirichlet', 'Random mix', 'Random embeddings'] {allow-input: true}\n",
    "optimize_class = True #@param {type:'boolean'}\n",
    "class_smoothing = 0.1 #@param {type:'number'}\n",
    "truncation = 1 #@param {type:'number'}\n",
    "stochastic_truncation = False #@param {type:'boolean'}\n",
    "optimizer = 'CMA-ES' #@param ['SGD','Adam','CMA-ES','CMA-ES + SGD interleaved','CMA-ES + Adam interleaved','CMA-ES + terminal SGD','CMA-ES + terminal Adam']\n",
    "pop_size = 50 #@param {type:'integer'}\n",
    "clip_model = 'ViT-B/32' #@param ['ViT-B/32','RN50','RN101','RN50x4']\n",
    "augmentations =  64#@param {type:'integer'}\n",
    "learning_rate =  0.1#@param {type:'number'}\n",
    "noise_normality_loss =  0#@param {type:'number'}\n",
    "embed_normality_loss = 0 #@param {type:'number'}\n",
    "minimum_entropy_loss = 0.0001 #@param {type:'number'}\n",
    "total_variation_loss = 0.1 #@param {type:'number'}\n",
    "# iterations = 100 #@param {type:'integer'}\n",
    "# terminal_iterations = 100 #@param {type:'integer'}\n",
    "\n",
    "# live POM\n",
    "iterations = iterations#20#100#40\n",
    "terminal_iterations = iterations\n",
    "show_every = 1 #@param {type:'integer'}\n",
    "save_every = 5 #@param {type:'integer'}\n",
    "fps = 1 #@param {type:'number'}\n",
    "freeze_secs = 0 #@param {type:'number'}\n",
    "\n",
    "# non-live POM\n",
    "# show_every = 1 #@param {type:'integer'}\n",
    "# save_every = 5 #@param {type:'integer'}\n",
    "# fps = 1 #@param {type:'number'}\n",
    "# freeze_secs = 0 #@param {type:'number'}\n",
    "# seed =  1#@param {type:'number'}\n",
    "\n",
    "\n",
    "softmax_temp = 1\n",
    "emb_factor = 0.067 #calculated empirically \n",
    "loss_factor = 100\n",
    "sigma0 = 0.5 #http://cma.gforge.inria.fr/cmaes_sourcecode_page.html#practical\n",
    "cma_adapt = True\n",
    "cma_diag = 'sigmoid' in gen_model\n",
    "cma_active = True\n",
    "cma_elitist = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generate\n",
    "\n",
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import sys\n",
    "import imageio\n",
    "from IPython.display import HTML, Image, clear_output\n",
    "from scipy.stats import truncnorm, dirichlet\n",
    "from pytorch_pretrained_biggan import BigGAN, convert_to_images, one_hot_from_names, utils\n",
    "from nltk.corpus import wordnet as wn\n",
    "#from base64 import b64encode\n",
    "from time import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeding (repeatable randomness):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if seed == 0:\n",
    "    seed = None\n",
    "    state = None\n",
    "else:\n",
    "    # torch.manual_seed(np.random.randint(sys.maxsize))\n",
    "    state = np.random.RandomState(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make output directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories are defined up top\n",
    "!rm -rf $outpath\n",
    "!mkdir -p $outpath\n",
    "!mkdir -p $resultspath\n",
    "!mkdir -p $storedpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise and class vector sizes\n",
    "noise_size = 128\n",
    "class_size = 128 if initial_class.lower()=='random embeddings' else 1000\n",
    "\n",
    "# load CLIP model unless we just used it\n",
    "if clip_model != last_clip_model:\n",
    "  perceptor, preprocess = clip.load(clip_model)\n",
    "  last_clip_model = clip_model\n",
    "  \n",
    "# image resolution, model name\n",
    "channels = 3 if color else 1\n",
    "clip_res = perceptor.input_resolution.item()\n",
    "sideX = sideY = int(size)\n",
    "gen_model = gen_model + '-' + size\n",
    "\n",
    "# load BigGAN model unless we just used it\n",
    "if gen_model != last_gen_model and 'biggan' in gen_model:\n",
    "  biggan_model = BigGAN.from_pretrained(gen_model).cuda().eval()\n",
    "  last_gen_model = gen_model\n",
    "\n",
    "# is our image smaller than the clip perceptor?\n",
    "if sideX<=clip_res and sideY<=clip_res:\n",
    "  augmentations = 1\n",
    "\n",
    "# for CMA we produce a population of candidate vectors, otherwise just 1 at a time\n",
    "if 'CMA' not in optimizer:\n",
    "  pop_size = 1\n",
    "\n",
    "# do not optimize class if not using BigGAN\n",
    "if 'biggan' not in gen_model:\n",
    "  optimize_class = False\n",
    "\n",
    "# BigGAN ImageNet class names to WordNet synsets/lemmas\n",
    "ind2name = {index: wn.of2ss('%08dn'%offset).lemma_names()[0] for offset, index in utils.IMAGENET.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_to_inplace_relu(model): #saves memory; from https://github.com/minyoungg/pix2latent/blob/master/pix2latent/model/biggan.py\n",
    "    for child_name, child in model.named_children():\n",
    "        if isinstance(child, nn.ReLU):\n",
    "            setattr(model, child_name, nn.ReLU(inplace=False))\n",
    "        else:\n",
    "            replace_to_inplace_relu(child)\n",
    "    return\n",
    "\n",
    "replace_to_inplace_relu(biggan_model)\n",
    "replace_to_inplace_relu(perceptor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image and vectors saving helpers: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(out,name=None):\n",
    "  with torch.no_grad():\n",
    "    out = out.cpu().numpy()\n",
    "  img = convert_to_images(out)[0]\n",
    "  if name:\n",
    "    imageio.imwrite(name, np.asarray(img))\n",
    "  return img\n",
    "\n",
    "def save_vec(out,name):\n",
    "  with torch.no_grad():\n",
    "    vec = out.cpu().numpy()\n",
    "  np.savetxt(name, vec)\n",
    "\n",
    "def save_all_vecs(out, name):\n",
    "  with torch.no_grad():\n",
    "    vec = out.cpu().numpy()\n",
    "  np.savetxt(name, vec)\n",
    "\n",
    "hist = []\n",
    "def checkin(i, best_ind, total_losses, losses, regs, out, noise=None, emb=None, probs=None):\n",
    "  global sample_num, hist\n",
    "  name = None\n",
    "  if save_every and i%save_every==0:\n",
    "    name = '%s/frame_%05d.jpg'%(outpath, sample_num)\n",
    "  pil_image = save(out, name)\n",
    "  vals0 = [sample_num, i, total_losses[best_ind], losses[best_ind], regs[best_ind], np.mean(total_losses), np.mean(losses), np.mean(regs), np.std(total_losses), np.std(losses), np.std(regs)]\n",
    "  stats = 'sample=%d iter=%d best: total=%.2f cos=%.2f reg=%.3f avg: total=%.2f cos=%.2f reg=%.3f std: total=%.2f cos=%.2f reg=%.3f'%tuple(vals0)\n",
    "  vals1 = []\n",
    "  if noise is not None:\n",
    "    vals1 = [np.mean(noise), np.std(noise)]\n",
    "    stats += ' noise: avg=%.2f std=%.3f'%tuple(vals1)\n",
    "  vals2 = []\n",
    "  if emb is not None:\n",
    "    vals2 = [emb.mean(),emb.std()]\n",
    "    stats += ' emb: avg=%.2f std=%.3f'%tuple(vals2)\n",
    "  elif probs:\n",
    "    best = probs[best_ind]\n",
    "    inds = np.argsort(best)[::-1]\n",
    "    probs = np.array(probs)\n",
    "    vals2 = [ind2name[inds[0]], best[inds[0]], ind2name[inds[1]], best[inds[1]], ind2name[inds[2]], best[inds[2]], np.sum(probs >= 0.5)/pop_size,np.sum(probs >= 0.3)/pop_size,np.sum(probs >= 0.1)/pop_size]\n",
    "    stats += ' 1st=%s(%.2f) 2nd=%s(%.2f) 3rd=%s(%.2f) components: >=0.5:%.0f, >=0.3:%.0f, >=0.1:%.0f'%tuple(vals2)\n",
    "  hist.append(vals0+vals1+vals2)\n",
    "  if show_every and i%show_every==0:\n",
    "    clear_output()\n",
    "    display(pil_image)  \n",
    "  print(stats)\n",
    "  print('Best index: %s' % best_ind)\n",
    "\n",
    "  # save best vectors\n",
    "  save_vec(noise_vector[best_ind], outpath+'noise_%05d.txt'%sample_num)\n",
    "  save_vec(class_vector[best_ind], outpath+'class_%05d.txt'%sample_num)  \n",
    "  sample_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN generation helpers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output(noise_vector, class_vector):\n",
    "  save_class_vector_norm = None\n",
    "  if 'sigmoid' in gen_model:\n",
    "    out = noise_vector.sigmoid().reshape(1, channels, sideY, sideX)*2-1\n",
    "  else:\n",
    "    if stochastic_truncation: #https://arxiv.org/abs/1702.04782\n",
    "      with torch.no_grad():\n",
    "        trunc_indices = noise_vector.abs() > 2*truncation\n",
    "        size = torch.count_nonzero(trunc_indices).cpu().numpy()\n",
    "        trunc = truncnorm.rvs(-2*truncation, 2*truncation, size=(1,size)).astype(np.float32)\n",
    "        noise_vector.data[trunc_indices] = torch.tensor(trunc, requires_grad=requires_grad, device='cuda')\n",
    "    else:\n",
    "      noise_vector = noise_vector.clamp(-2*truncation, 2*truncation)\n",
    "    if initial_class.lower() == 'random embeddings':\n",
    "      class_vector_norm = class_vector*emb_factor\n",
    "    else:\n",
    "      class_vector_norm = torch.softmax(class_vector/softmax_temp,dim=-1)\n",
    "    out = biggan_model(noise_vector, class_vector_norm, truncation)\n",
    "    if channels==1:\n",
    "      out = out.mean(dim=1, keepdim=True)\n",
    "    if initial_class.lower() != 'random embeddings':\n",
    "      save_class_vector_norm = class_vector_norm\n",
    "  if channels==1:\n",
    "    out = out.repeat(1,3,1,1)\n",
    "  return out, save_class_vector_norm\n",
    "\n",
    "# define forward pass\n",
    "def my_forward(self, z, class_label, truncation):\n",
    "  assert 0 < truncation <= 1\n",
    "\n",
    "  if initial_class.lower()=='random embeddings':\n",
    "    embed = class_label\n",
    "  else:\n",
    "    embed = self.embeddings(class_label)\n",
    "    \n",
    "  cond_vector = torch.cat((z, embed), dim=1)\n",
    "\n",
    "  z = self.generator(cond_vector, truncation)\n",
    "  return z\n",
    "\n",
    "# set forward pass\n",
    "if gen_model == 'biggan':\n",
    "    BigGAN.forward = my_forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text optimization helpers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normality_loss(vec): #https://arxiv.org/abs/1903.00925\n",
    "    mu2 = vec.mean().square()\n",
    "    sigma2 = vec.var()\n",
    "    return mu2+sigma2-torch.log(sigma2)-1\n",
    "\n",
    "def make_safe_filename(s):\n",
    "    def safe_char(c):\n",
    "        if c.isalnum():\n",
    "            return c\n",
    "        else:\n",
    "            return \"_\"\n",
    "    return \"\".join(safe_char(c) for c in s).rstrip(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $outpath\n",
    "!mkdir -p $resultspath\n",
    "\n",
    "requires_grad = ('SGD' in optimizer or 'Adam' in optimizer) and ('terminal' not in optimizer or terminal_iterations>0)\n",
    "total_iterations = iterations + terminal_iterations*('terminal' in optimizer)\n",
    "\n",
    "# ====\n",
    "# NOT EDITED BELOW\n",
    "\n",
    "for prompt in prompts:\n",
    "    \n",
    "    # initialization\n",
    "    eps = 1e-8\n",
    "    class_vector = None\n",
    "    if 'sigmoid' in gen_model:\n",
    "      noise_size = channels*sideY*sideX\n",
    "      noise_vector = np.random.rand(pop_size, noise_size).astype(np.float32)\n",
    "      noise_vector = np.log((noise_vector+eps)/(1-noise_vector+eps))\n",
    "    else:\n",
    "      noise_vector = truncnorm.rvs(-2*truncation, 2*truncation, size=(pop_size, noise_size), random_state=state).astype(np.float32) #see https://github.com/tensorflow/hub/issues/214\n",
    "\n",
    "      if initial_class.lower() == 'random class':\n",
    "        class_vector = np.ones(shape=(pop_size, class_size), dtype=np.float32)*class_smoothing/999\n",
    "        class_vector[0,np.random.randint(class_size)] = 1-class_smoothing\n",
    "      elif initial_class.lower() == 'random dirichlet':\n",
    "        class_vector = dirichlet.rvs([pop_size/class_size] * class_size, size=1, random_state=state).astype(np.float32)\n",
    "      elif initial_class.lower() == 'random mix':\n",
    "        class_vector = np.random.rand(pop_size, class_size).astype(np.float32)\n",
    "      elif initial_class.lower() == 'random embeddings':\n",
    "        class_vector = np.random.randn(pop_size, class_size).astype(np.float32)\n",
    "      else:\n",
    "        if initial_class.lower() == 'from prompt':\n",
    "          initial_class = prompt\n",
    "        try:\n",
    "          class_vector = None\n",
    "          class_vector = one_hot_from_names(initial_class, batch_size=pop_size)\n",
    "          assert class_vector is not None\n",
    "          class_vector = class_vector*(1-class_smoothing*class_size/(class_size-1))+class_smoothing/(class_size-1)\n",
    "        except Exception as e:  \n",
    "          print('Error: could not find initial_class. Try something else.')\n",
    "          raise e\n",
    "\n",
    "      if initial_class.lower() != 'random embeddings':\n",
    "        class_vector = class_vector/np.sum(class_vector,axis=-1, keepdims=True)\n",
    "        class_vector = np.log(class_vector+eps)-np.mean(np.log(class_vector+eps),axis=-1, keepdims=True)\n",
    "      initial_class_vector = class_vector[0]\n",
    "      if initial_class.lower() in ('random mix','random embeddings'):\n",
    "        initial_class_vector = initial_class_vector*0\n",
    "      class_vector = torch.tensor(class_vector, requires_grad=requires_grad, device='cuda')\n",
    "      smoothed_ent = -torch.tensor(class_smoothing*np.log(class_smoothing/999+eps)+(1-class_smoothing)*np.log(1-class_smoothing+eps), dtype=torch.float32).cuda()\n",
    "    noise_vector = torch.tensor(noise_vector, requires_grad=requires_grad, device='cuda')\n",
    "\n",
    "    if requires_grad:\n",
    "      params = [noise_vector]\n",
    "      if optimize_class:\n",
    "        params = params + [class_vector]\n",
    "      if 'SGD' in optimizer:\n",
    "        optim = torch.optim.SGD(params, lr=learning_rate, momentum=0.9)  \n",
    "      else:\n",
    "        optim = torch.optim.Adam(params, lr=learning_rate)\n",
    "\n",
    "    # convert prompt to tokenized target\n",
    "    tx = clip.tokenize(prompt)\n",
    "    with torch.no_grad():\n",
    "      target_clip = perceptor.encode_text(tx.cuda())\n",
    "    \n",
    "    # store best results as we optimize this prompt\n",
    "    global_best_loss = np.inf\n",
    "    global_best_iteration = 0\n",
    "    global_best_noise_vector = None\n",
    "    global_best_class_vector = None\n",
    "\n",
    "    # ascend the text\n",
    "    def ascend_txt(i, grad_step=False, show_save=False):\n",
    "      global global_best_loss, global_best_iteration, global_best_noise_vector, global_best_class_vector\n",
    "      prev_class_vector_norms = []\n",
    "      regs = []\n",
    "      losses = []\n",
    "      total_losses = []\n",
    "      best_loss = np.inf\n",
    "      global_reg = torch.tensor(0, device='cuda', dtype=torch.float32, requires_grad=grad_step)\n",
    "      if 'biggan' in gen_model:\n",
    "        if optimize_class and embed_normality_loss and initial_class.lower() == 'random embeddings':\n",
    "          global_reg = global_reg+embed_normality_loss*normality_loss(class_vector)\n",
    "        if noise_normality_loss:\n",
    "          global_reg = global_reg+noise_normality_loss*normality_loss(noise_vector)\n",
    "        global_reg = loss_factor*global_reg  \n",
    "        if grad_step:\n",
    "          global_reg.backward()\n",
    "      for j in range(pop_size):\n",
    "        p_s = []\n",
    "        out, class_vector_norm = get_output(noise_vector[j:j+1], None if class_vector is None else class_vector[j:j+1])\n",
    "        if class_vector_norm is not None:\n",
    "          with torch.no_grad():\n",
    "            prev_class_vector_norms.append(class_vector_norm.cpu().numpy()[0])\n",
    "\n",
    "        for aug in range(augmentations):\n",
    "          if sideX<=clip_res and sideY<=clip_res or augmentations==1:\n",
    "            apper = out  \n",
    "          else:\n",
    "            size = torch.randint(int(.7*sideX), int(.98*sideX), ())\n",
    "            offsetx = torch.randint(0, sideX - size, ())\n",
    "            offsety = torch.randint(0, sideX - size, ())\n",
    "            apper = out[:, :, offsetx:offsetx + size, offsety:offsety + size]\n",
    "          apper = (apper+1)/2\n",
    "          apper = nn.functional.interpolate(apper, clip_res, mode='bilinear')\n",
    "          #apper = apper.clamp(0,1)\n",
    "          p_s.append(apper)\n",
    "        into = nom(torch.cat(p_s, 0))\n",
    "        predict_clip = perceptor.encode_image(into)\n",
    "        loss = loss_factor*(1-torch.cosine_similarity(predict_clip, target_clip).mean())\n",
    "        \n",
    "#         print(\"tokens:\", tx)\n",
    "#         print(\"target clip:\", target_clip)\n",
    "#         print(\"predict clip:\",predict_clip)\n",
    "#         print(\"cosine_sim:\", torch.cosine_similarity(predict_clip, target_clip).mean())\n",
    "#         sys.exit()\n",
    "\n",
    "        total_loss = loss\n",
    "        regs.append(global_reg.item())\n",
    "        if 'sigmoid' in gen_model and total_variation_loss or 'biggan' in gen_model and optimize_class and minimum_entropy_loss and initial_class.lower() != 'random embeddings':\n",
    "          if 'sigmoid' in gen_model and total_variation_loss:\n",
    "            reg = total_variation_loss*((out[:, :, :-1, :] - out[:, :, 1:, :]).abs().mean() + (out[:, :, :, :-1] - out[:, :, :, 1:]).abs().mean())\n",
    "          elif 'biggan' in gen_model and optimize_class and minimum_entropy_loss and initial_class.lower() != 'random embeddings':\n",
    "            reg = minimum_entropy_loss*((-class_vector_norm*torch.log(class_vector_norm+eps)).sum()-smoothed_ent).abs()\n",
    "          reg = loss_factor*reg\n",
    "          total_loss = total_loss + reg\n",
    "          with torch.no_grad():\n",
    "            regs[-1] += reg.item()\n",
    "        with torch.no_grad():\n",
    "          losses.append(loss.item())\n",
    "          total_losses.append(total_loss.item()+global_reg.item())\n",
    "        if total_losses[-1]<best_loss:\n",
    "          best_loss = total_losses[-1]\n",
    "          best_ind = j\n",
    "          best_out = out\n",
    "          if best_loss < global_best_loss:\n",
    "            global_best_loss = best_loss\n",
    "            global_best_iteration = i\n",
    "            with torch.no_grad():\n",
    "              global_best_noise_vector = noise_vector[best_ind]\n",
    "              if class_vector is not None:\n",
    "                global_best_class_vector = class_vector[best_ind]\n",
    "\n",
    "        if grad_step:    \n",
    "          total_loss.backward()\n",
    "\n",
    "      if grad_step:\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "\n",
    "      if show_save and (save_every and i % save_every == 0 or show_every and i % show_every == 0):\n",
    "        noise = None\n",
    "        emb = None\n",
    "        if 'biggan' in gen_model:\n",
    "          with torch.no_grad():\n",
    "            noise = noise_vector.cpu().numpy()\n",
    "            if initial_class.lower() == 'random embeddings':\n",
    "              emb = class_vector.cpu().numpy()\n",
    "        checkin(i, best_ind, total_losses, losses, regs, best_out, noise, emb, prev_class_vector_norms)  \n",
    "      return total_losses, best_ind\n",
    "\n",
    "    nom = torchvision.transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
    "    if 'CMA' in optimizer:\n",
    "      initial_vector = np.zeros(noise_size)\n",
    "      bounds = None\n",
    "      #if 'biggan' in gen_model and not stochastic_truncation:\n",
    "      #  bounds = [-2*truncation*np.ones(noise_size),2*truncation*np.ones(noise_size)]\n",
    "      if optimize_class:\n",
    "        initial_vector = np.hstack([initial_vector, initial_class_vector])\n",
    "        #if not stochastic_truncation:\n",
    "        #  bounds[0] = list(bounds[0]) + [None]*class_size\n",
    "        #  bounds[1] = list(bounds[1]) + [None]*class_size\n",
    "      cma_opts = {'popsize': pop_size, 'seed': np.nan, 'AdaptSigma': cma_adapt, 'CMA_diagonal': cma_diag, 'CMA_active': cma_active, 'CMA_elitist':cma_elitist, 'bounds':bounds}\n",
    "      cmaes = cma.CMAEvolutionStrategy(initial_vector, sigma0, inopts=cma_opts)\n",
    "\n",
    "    sample_num = 0\n",
    "    machine = !nvidia-smi -L\n",
    "    start = time()\n",
    "    for i in range(total_iterations):    \n",
    "      if 'CMA' in optimizer and i<iterations:\n",
    "        with torch.no_grad():\n",
    "          cma_results = torch.tensor(cmaes.ask(), dtype=torch.float32).cuda()\n",
    "          if optimize_class:\n",
    "            noise_vector.data, class_vector.data = torch.split_with_sizes(cma_results, (noise_size, class_size), dim=-1)\n",
    "            class_vector.data = class_vector.data\n",
    "          else:\n",
    "            noise_vector.data = cma_results      \n",
    "      if requires_grad and ('terminal' not in optimizer or i>=iterations):\n",
    "        losses, best_ind = ascend_txt(i, grad_step=True, show_save='CMA' not in optimizer or i>=iterations)\n",
    "        assert noise_vector.requires_grad and noise_vector.is_leaf and (not optimize_class or class_vector.requires_grad and class_vector.is_leaf), (noise_vector.requires_grad, noise_vector.is_leaf, class_vector.requires_grad, class_vector.is_leaf)\n",
    "      if 'CMA' in optimizer and i<iterations:\n",
    "        with torch.no_grad():\n",
    "          losses, best_ind = ascend_txt(i, show_save=True)\n",
    "          if i<iterations-1:\n",
    "            if optimize_class:\n",
    "              vectors = torch.cat([noise_vector,class_vector], dim=1)\n",
    "            else:\n",
    "              vectors = noise_vector\n",
    "            cmaes.tell(vectors.cpu().numpy(), losses)\n",
    "          elif 'terminal' in optimizer and terminal_iterations:\n",
    "            pop_size = 1\n",
    "            noise_vector[0] = global_best_noise_vector\n",
    "            if class_vector is not None:\n",
    "              class_vector[0] = global_best_class_vector\n",
    "      if save_every and i % save_every == 0 or show_every and i % show_every == 0:\n",
    "        print('took: %d secs (%.2f sec/iter) on %s. CUDA memory: %.1f GB'%(time()-start,(time()-start)/(i+1), machine[0], torch.cuda.max_memory_allocated()/1024**3))\n",
    "        print('global best iteration: %d' % global_best_iteration)\n",
    "        print('prompt: %s' % prompt)\n",
    "        #print('prompt: %s, target-CLIP: %s' % (prompt, target_clip))\n",
    "\n",
    "    # from modified BigCLIP\n",
    "    # prompt_safe = prompt.replace(\" \",\"_\")\n",
    "    # results_timestamp = resultspath+'%s_%s' % (prompt_safe, datetime.datetime.now().strftime('%Y%m%d_%H%M%S'))\n",
    "    # save(best_out, results_timestamp+'.jpg')\n",
    "    # save_vec(noise_vector[best_ind], results_timestamp+'_noise.txt')\n",
    "    # save_vec(class_vector[best_ind], results_timestamp+'_class.txt')\n",
    "\n",
    "#     prompt_safe = prompt.replace(\" \",\"_\")\n",
    "    prompt_safe = make_safe_filename(prompt)\n",
    "    out, _ = get_output(global_best_noise_vector.unsqueeze(0), None if global_best_class_vector is None else global_best_class_vector.unsqueeze(0))\n",
    "    name = '%s/%s.jpg'%(resultspath, prompt_safe)\n",
    "    pil_image = save(out,name)\n",
    "    save_vec(global_best_noise_vector, '%s/%s_noise.txt' % (resultspath, prompt_safe))\n",
    "    save_vec(global_best_class_vector, '%s/%s_class.txt' % (resultspath, prompt_safe))\n",
    "\n",
    "    display(pil_image)  \n",
    "    print('best_loss=%.2f best_iter=%d'%(global_best_loss,global_best_iteration))\n",
    "\n",
    "    # move outputs to saved path with datestampt\n",
    "#     newdir = outpath[:-1]+\"_\"+prompt_safe+\"_\"+datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "#     newdir = storedpath+prompt_safe+\"_\"+datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    newdir_timestamp = storedpath+prompt_safe+\"_\"+datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    newdir = storedpath+prompt_safe\n",
    "    !mv $outpath $newdir_timestamp\n",
    "    !ln -s $newdir_timestamp $newdir\n",
    "    !mkdir -p $outpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Based on SIREN+CLIP Colabs by: [@advadnoun](https://twitter.com/advadnoun), [@norod78](https://twitter.com/norod78)\n",
    "\n",
    "Using the works:\n",
    "\n",
    "https://github.com/openai/CLIP\n",
    "\n",
    "https://tfhub.dev/deepmind/biggan-deep-512\n",
    "\n",
    "https://github.com/huggingface/pytorch-pretrained-BigGAN\n",
    "\n",
    "http://www.aiartonline.com/design-2019/eyal-gruss (WanderGAN)\n",
    "\n",
    "Other CLIP notebooks: https://www.reddit.com/r/MachineLearning/comments/ldc6oc/p_list_of_sitesprogramsprojects_that_use_openais\n",
    "\n",
    "A curated list of more online generative tools see: [j.mp/generativetools](https://j.mp/generativetools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leftovers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "leftover prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# prompts = [\n",
    "#     \"over my head, I see the bronze butterfly\",\n",
    "#     \"asleep on the black trunk\",\n",
    "#     \"blowing like a leaf in green shadow\",   \n",
    "#     \"down the ravine behind the empty house\",   \n",
    "#     \"the cowbells follow one another\",   \n",
    "#     \"into the distances of the afternoon\",   \n",
    "#     \"to my right\",\n",
    "#     \"in a field of sunlight between two pines\",   \n",
    "#     \"the droppings of last year’s horses\",   \n",
    "#     \"blaze up into golden stones\",\n",
    "#     \"I lean back, as the evening darkens and comes on\",\n",
    "#     \"a chicken hawk floats over, looking for home\",\n",
    "#     \"I have wasted my life\"\n",
    "# ]\n",
    "\n",
    "# prompts = [\n",
    "#     \"Midway on our lifes journey, I found myself\",\n",
    "#     \"In dark woods, the right road lost\",\n",
    "#     \"To tell About those woods is hard - so tangled and rough\",\n",
    "#     \"And savage that thinking of it now, I feel\",\n",
    "#     \"The old fear stirring: death is hardly more bitter.\",\n",
    "#     \"And yet, to treat the good I found there as well\",\n",
    "#     \"I'll tell what I saw, though how I came to enter\",\n",
    "#     \"I cannot well say, being so full of sleep\",\n",
    "#     \"Whatever moment it was I began to blunder\",\n",
    "#     \"Off the true path. But when I came to stop\",\n",
    "#     \"Below a hill that marked one end of the valley\",\n",
    "#     \"That had pierced my heart with terror, I looked up\",\n",
    "#     \"Toward the crest and saw its shoulders already\",\n",
    "#     \"Mantled in rays of that bright planet that shows\",\n",
    "#     \"The road to everyone, whatever our journey.\",\n",
    "#     \"Then I could feel the terror begin to ease\",\n",
    "#     \"That churned in my heart's lake all through the night.\",\n",
    "#     \"As one still panting, ashore from dangerous seas\",\n",
    "#     \"Looks back at the deep he has escaped, my thought\",\n",
    "#     \"Returned, still fleeing, to regard that grim defile\", \n",
    "#     \"That never left any alive who stayed in it.\"\n",
    "# ]\n",
    "\n",
    "# prompts = [\n",
    "#     'a photo of wild tarragon',\n",
    "#     'a drawing of wild tarragon, a tasteless plant',\n",
    "#     'a painting of farm hands, a kind of laborer',\n",
    "#     'a painting of a farmer’s hands',\n",
    "#     'a self-portrait of Artemisia Gentileschi, artist',\n",
    "#     'artemisia Gentileschi is a dragon',\n",
    "#     'a painting of Artemisia Gentileschi as a dragon',\n",
    "#     'a photo of the dragon Artemisia Gentileschi',\n",
    "#     'a portrait of artist as dragon',\n",
    "#     'a drawing of a dragon',\n",
    "#     'a painting of uprooted rhizome as a dragon',\n",
    "#     'a sketch of a rhizome, uprooted',\n",
    "#     'an image of a plant rising',\n",
    "#     'a drawing of plant roots and mycorrhizal fungi',\n",
    "#     'an image of growing wiser',\n",
    "#     'a painting of wise plants',\n",
    "#     'a drawing of plant wisdom',\n",
    "#     'a photo of a plant hiding',\n",
    "#     'a drawing of hiding from elders',\n",
    "#     'a painting of Susanna and the Elders',\n",
    "#     'an image of creeps',\n",
    "#     'a painting of gazing creeps',\n",
    "#     'a painting of groping creeps',\n",
    "#     'a painting of invasive elders',\n",
    "#     'a photo of perverse hope',\n",
    "#     'a painting of your hatred',\n",
    "#     'a drawing of killing a mosquito',\n",
    "#     'a painting of a mosquito, a kind of corpse',\n",
    "#     'a drawing of malaria',\n",
    "#     'a sketch of salted fields',\n",
    "#     'a photo of dancers',\n",
    "#     'a painting of dancers in a field',\n",
    "#     'an image of your spit',\n",
    "#     'a photo of standing too close',\n",
    "#     'a painting of someone standing too close',\n",
    "#     'a drawing of an oak sapling',\n",
    "#     'a painting of an oak in an empty field',\n",
    "#     'a photo of growing',\n",
    "#     'an image of growing wilder',\n",
    "#     'a painting of growing stronger',\n",
    "#     'a photo of a hand holding high',\n",
    "#     'a painting of a hand holding the head of Holofernes',\n",
    "#     'a painting of the head of Holofernes',\n",
    "#     'a drawing of a head, blood-rooted',\n",
    "#     'an image of a bloody root',\n",
    "#     'a painting of autumn gold',\n",
    "#     'a photo of a golden gown',\n",
    "#     'an image of a mouth tasting',\n",
    "#     'a sketch of a mouth',\n",
    "#     'a drawing of taste',\n",
    "#     'a painting of the taste of nothing',\n",
    "#     'a photograph of being invisible',\n",
    "#     'a drawing of your renown',\n",
    "#     'a painting of a renowned artist',\n",
    "#     'a portrait of the artist',\n",
    "#     'a self-portrait of Artemisia Gentileschi as tarragon'\n",
    "# ]\n",
    "\n",
    "# prompts = [\n",
    "#     \"sunrise through a window\",\n",
    "#     \"a cat in the refrigerator\"\n",
    "#     \"microsoft basic on a tandy 1000\"\n",
    "#     \"a canvas on an easel in a field\",\n",
    "#     \"a painter painting on an easel in a field\",\n",
    "#     \"a painting on an easel in the landscape\"\n",
    "# ]\n",
    "\n",
    "# prompts = [\n",
    "#     \"sunrise through a window\",\n",
    "#     \"a cat in the refrigerator\"\n",
    "# ]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPwm65R9PqvNtVnT2ePL9Uh",
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "WanderCLIP.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
