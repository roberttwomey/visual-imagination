{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwTP4MYk0bYn"
   },
   "source": [
    "# Artificial Visual Imagination \n",
    "## Text to Image with BigGAN + CLIP + CMA-ES\n",
    "\n",
    "---\n",
    "\n",
    "BIGCLIP [j.mp/bigclip](https://j.mp/bigclip) by Eyal Gruss [@eyaler](https://twitter.com/eyaler) [eyalgruss.com](https://eyalgruss.com)\n",
    "\n",
    "\n",
    "Modified to run on nautilus.optiputer.net by robert.twomey@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Here, Then Run All\n",
    "\n",
    "Results show up in `/work/results/` in the file browser at left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompts = [\n",
    "#     'sculpture television buddha',\n",
    "#     'television buddha sculpture with grass',\n",
    "#     'a buddha sculpture with television in the grass',\n",
    "#     'old television in grass with buddha sculpture by pacific ocean',\n",
    "#     'old television in long grass with buddha sculpture by pacific ocean'\n",
    "# ]\n",
    "\n",
    "# prompts = [\n",
    "#     'a photo of wild tarragon',\n",
    "#     'a drawing of wild tarragon, a tasteless plant',\n",
    "#     'a painting of farm hands, a kind of laborer',\n",
    "#     'a painting of a farmer’s hands',\n",
    "#     'a self-portrait of Artemisia Gentileschi, artist',\n",
    "#     'artemisia Gentileschi is a dragon',\n",
    "#     'a painting of Artemisia Gentileschi as a dragon',\n",
    "#     'a photo of the dragon Artemisia Gentileschi',\n",
    "#     'a portrait of artist as dragon',\n",
    "#     'a drawing of a dragon',\n",
    "#     'a painting of uprooted rhizome as a dragon',\n",
    "#     'a sketch of a rhizome, uprooted',\n",
    "#     'an image of a plant rising',\n",
    "#     'a drawing of plant roots and mycorrhizal fungi',\n",
    "#     'an image of growing wiser',\n",
    "#     'a painting of wise plants',\n",
    "#     'a drawing of plant wisdom',\n",
    "#     'a photo of a plant hiding',\n",
    "#     'a drawing of hiding from elders',\n",
    "#     'a painting of Susanna and the Elders',\n",
    "#     'an image of creeps',\n",
    "#     'a painting of gazing creeps',\n",
    "#     'a painting of groping creeps',\n",
    "#     'a painting of invasive elders',\n",
    "#     'a photo of perverse hope',\n",
    "#     'a painting of your hatred',\n",
    "#     'a drawing of killing a mosquito',\n",
    "#     'a painting of a mosquito, a kind of corpse',\n",
    "#     'a drawing of malaria',\n",
    "#     'a sketch of salted fields',\n",
    "#     'a photo of dancers',\n",
    "#     'a painting of dancers in a field',\n",
    "#     'an image of your spit',\n",
    "#     'a photo of standing too close',\n",
    "#     'a painting of someone standing too close',\n",
    "#     'a drawing of an oak sapling',\n",
    "#     'a painting of an oak in an empty field',\n",
    "#     'a photo of growing',\n",
    "#     'an image of growing wilder',\n",
    "#     'a painting of growing stronger',\n",
    "#     'a photo of a hand holding high',\n",
    "#     'a painting of a hand holding the head of Holofernes',\n",
    "#     'a painting of the head of Holofernes',\n",
    "#     'a drawing of a head, blood-rooted',\n",
    "#     'an image of a bloody root',\n",
    "#     'a painting of autumn gold',\n",
    "#     'a photo of a golden gown',\n",
    "#     'an image of a mouth tasting',\n",
    "#     'a sketch of a mouth',\n",
    "#     'a drawing of taste',\n",
    "#     'a painting of the taste of nothing',\n",
    "#     'a photograph of being invisible',\n",
    "#     'a drawing of your renown',\n",
    "#     'a painting of a renowned artist',\n",
    "#     'a portrait of the artist',\n",
    "#     'a self-portrait of Artemisia Gentileschi as tarragon'\n",
    "# ]\n",
    "\n",
    "# prompts = [\n",
    "#     'a photo of a front door',\n",
    "#     'a picture of the mud room',\n",
    "#     'a photo of the kitchen', \n",
    "#     'a photo of the livingroom with television', \n",
    "#     'a photo of a couch and a television', \n",
    "#     'a photo of a family on a couch', \n",
    "#     'a picture a kitchen', \n",
    "#     'a photo of food on the kitchen counter',\n",
    "#     'a photo of a pie in the oven',\n",
    "#     'a photo of a bathroom',\n",
    "#     'a photo of the interior of a bathroom',\n",
    "#     'a photo of a person in a shower', \n",
    "#     'a photo of person brushing their teeth',\n",
    "#     'a picture of the interior of a bedroom',\n",
    "#     'a picture of a person sleeping in a bed', \n",
    "#     'a photo of a sunrise through a window'\n",
    "# ]\n",
    "\n",
    "# prompts = [\n",
    "#     \"sunrise through a window\",\n",
    "#     \"a cat in the refrigerator\"\n",
    "# ]\n",
    "\n",
    "# prompts = [\n",
    "#     \"over my head, I see the bronze butterfly\",\n",
    "#     \"asleep on the black trunk\",\n",
    "#     \"blowing like a leaf in green shadow\",   \n",
    "#     \"down the ravine behind the empty house\",   \n",
    "#     \"the cowbells follow one another\",   \n",
    "#     \"into the distances of the afternoon\",   \n",
    "#     \"to my right\",\n",
    "#     \"in a field of sunlight between two pines\",   \n",
    "#     \"the droppings of last year’s horses\",   \n",
    "#     \"blaze up into golden stones\",\n",
    "#     \"I lean back, as the evening darkens and comes on\",\n",
    "#     \"a chicken hawk floats over, looking for home\",\n",
    "#     \"I have wasted my life\"\n",
    "# ]\n",
    "\n",
    "prompts = [\n",
    "    \"Midway on our life's journey, I found myself\",\n",
    "    \"In dark woods, the right road lost\",\n",
    "    \"To tell About those woods is hard - so tangled and rough\",\n",
    "    \"And savage that thinking of it now, I feel\",\n",
    "    \"The old fear stirring: death is hardly more bitter.\",\n",
    "    \"And yet, to treat the good I found there as well\",\n",
    "    \"I'll tell what I saw, though how I came to enter\",\n",
    "    \"I cannot well say, being so full of sleep\",\n",
    "    \"Whatever moment it was I began to blunder\",\n",
    "    \"Off the true path. But when I came to stop\",\n",
    "    \"Below a hill that marked one end of the valley\",\n",
    "    \"That had pierced my heart with terror, I looked up\",\n",
    "    \"Toward the crest and saw its shoulders already\",\n",
    "    \"Mantled in rays of that bright planet that shows\",\n",
    "    \"The road to everyone, whatever our journey.\",\n",
    "    \"Then I could feel the terror begin to ease\",\n",
    "    \"That churned in my heart's lake all through the night.\",\n",
    "    \"As one still panting, ashore from dangerous seas\",\n",
    "    \"Looks back at the deep he has escaped, my thought\",\n",
    "    \"Returned, still fleeing, to regard that grim defile\", \n",
    "    \"That never left any alive who stayed in it.\"\n",
    "]\n",
    "\n",
    "seed = 9#1#3\n",
    "iterations = 40#100#40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports to start session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "from pytorch_pretrained_biggan import BigGAN\n",
    "# load BigGAN below\n",
    "last_gen_model = None\n",
    "# last_gen_model = 'biggan-deep-512'\n",
    "# biggan_model = BigGAN.from_pretrained(last_gen_model).cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/visual-imagination/CLIP\n"
     ]
    }
   ],
   "source": [
    "cd CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip # load CLIP below\n",
    "last_clip_model = None\n",
    "# last_clip_model = 'ViT-B/32'\n",
    "# perceptor, preprocess = clip.load(last_clip_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RN50', 'ViT-B/32']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit your prompt below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = 'television buddha sculpture with grass'\n",
    "# prompt = 'a buddha sculpture with television in the grass'\n",
    "# prompt = 'buddha television grass'\n",
    "# prompt = \"a clean well-lighted place\"\n",
    "# prompt = \"large bright white room fluorescent light\"\n",
    "# prompt = \"a room with good lighting\"\n",
    "\n",
    "gen_model = 'biggan-deep' #@param ['biggan-deep', 'sigmoid']\n",
    "size = '512' #@param [512, 256, 128] \n",
    "color = True #@param {type:'boolean'}\n",
    "initial_class = 'Random mix' #@param ['From prompt', 'Random class', 'Random Dirichlet', 'Random mix', 'Random embeddings'] {allow-input: true}\n",
    "optimize_class = True #@param {type:'boolean'}\n",
    "class_smoothing = 0.1 #@param {type:'number'}\n",
    "truncation = 1 #@param {type:'number'}\n",
    "stochastic_truncation = False #@param {type:'boolean'}\n",
    "optimizer = 'CMA-ES' #@param ['SGD','Adam','CMA-ES','CMA-ES+SGD','CMA-ES+Adam']\n",
    "pop_size = 50 #@param {type:'integer'}\n",
    "clip_model = 'ViT-B/32' #@param ['ViT-B/32','RN50']\n",
    "augmentations =  64#@param {type:'integer'}\n",
    "learning_rate =  0.1#@param {type:'number'}\n",
    "standartization_loss =  0#@param {type:'number'}\n",
    "minimum_entropy_loss = 0.0001 #@param {type:'number'}\n",
    "embeddings_l2_loss = 0.0001 #@param {type:'number'}\n",
    "total_variation_loss = 0.1 #@param {type:'number'}\n",
    "save_every = 5 #@param {type:'integer'}\n",
    "fps = 1 #@param {type:'number'}\n",
    "freeze_secs = 0 #@param {type:'number'}\n",
    "\n",
    "# iterations = 10 #@param {type:'integer'}\n",
    "# seed =  0#@param {type:'number'}\n",
    "# seed = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For **prompt** OpenAI suggest to use the template \"A photo of a X.\" or \"A photo of a X, a type of Y.\" [[paper]](https://cdn.openai.com/papers/Learning_Transferable_Visual_Models_From_Natural_Language_Supervision.pdf)\n",
    "2. For **initial_class** you can either use free text or select a special option from the drop-down list.\n",
    "3. Free text and 'From prompt' might fail to find an appropriate ImageNet class.\n",
    "4. **seed**=0 means no seed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and helpers: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import sys\n",
    "import imageio\n",
    "from IPython.display import HTML, Image, clear_output\n",
    "from scipy.stats import truncnorm, dirichlet\n",
    "from pytorch_pretrained_biggan import BigGAN, convert_to_images, one_hot_from_names, utils\n",
    "from nltk.corpus import wordnet as wn\n",
    "#from base64 import b64encode\n",
    "from time import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f54efd4adb0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seeding\n",
    "if seed == 0:\n",
    "  seed = None\n",
    "\n",
    "# torch.manual_seed(np.random.randint(sys.maxsize))\n",
    "state = None if not seed else np.random.RandomState(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellView": "form",
    "id": "AOWzPLrBbdxW"
   },
   "outputs": [],
   "source": [
    "# noise and class vector sizes\n",
    "noise_size = 128\n",
    "class_size = 128 if initial_class.lower()=='random embeddings' else 1000\n",
    "\n",
    "# load CLIP model unless we just used it\n",
    "if clip_model != last_clip_model:\n",
    "  perceptor, preprocess = clip.load(clip_model)\n",
    "  last_clip_model = clip_model\n",
    "\n",
    "# image resolution, model name\n",
    "channels = 3 if color else 1\n",
    "clip_res = perceptor.input_resolution.item()\n",
    "gen_model = gen_model + '-' + size\n",
    "sideX = sideY = int(size)\n",
    "\n",
    "# load BigGAN model unless we just used it\n",
    "if gen_model != last_gen_model and 'biggan' in gen_model:\n",
    "  biggan_model = BigGAN.from_pretrained(gen_model).cuda().eval()\n",
    "  last_gen_model = gen_model\n",
    "    \n",
    "# is our image smaller than the clip perceptor?\n",
    "if sideX<=clip_res and sideY<=clip_res:\n",
    "  augmentations = 1\n",
    "  print(\"augmentations\")\n",
    "\n",
    "# for CMA we produce a population of candidate vectors\n",
    "if 'CMA' not in optimizer:\n",
    "  pop_size = 1\n",
    "\n",
    "# settings for sigmoid generation\n",
    "if 'sigmoid' in gen_model:\n",
    "  optimize_class = False\n",
    "emb_factor = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cma\n",
    "from cma.sigma_adaptation import CMAAdaptSigmaCSA, CMAAdaptSigmaTPA\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", cma.evolution_strategy.InjectionWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet/WordNet\n",
    "ind2name = {index: wn.of2ss('%08dn'%offset).lemma_names()[0] for offset, index in utils.IMAGENET.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward pass:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(out,name):\n",
    "  with torch.no_grad():\n",
    "    out = out.cpu().numpy()\n",
    "  if 'sigmoid' in gen_model:\n",
    "    out = out*2 - 1\n",
    "  img = convert_to_images(out)[0] # saves the first image\n",
    "  imageio.imwrite(name, np.asarray(img))\n",
    "\n",
    "def save_vec(out,name):\n",
    "  with torch.no_grad():\n",
    "    vec = out.cpu().numpy()\n",
    "  np.savetxt(name, vec)\n",
    "\n",
    "def save_all_vecs(out, name):\n",
    "  with torch.no_grad():\n",
    "    vec = out.cpu().numpy()\n",
    "  np.savetxt(name, vec)\n",
    "    \n",
    "def checkin(i, best_ind, total_losses, losses, regs, out, probs=None):\n",
    "  global sample_num\n",
    "  name = outpath+'frame_%05d.jpg'%sample_num\n",
    "  save(out, name)\n",
    "  clear_output()\n",
    "  display(Image(name))  \n",
    "  stats = 'sample=%d iter=%d best: total=%.2f cos=%.2f reg=%.3f avg: total=%.2f cos=%.2f reg=%.3f std: total=%.2f cos=%.2f reg=%.3f'%(sample_num, i, total_losses[best_ind], losses[best_ind], regs[best_ind], np.mean(total_losses), np.mean(losses), np.mean(regs), np.std(total_losses), np.std(losses), np.std(regs))\n",
    "  \n",
    "  if probs is not None:\n",
    "    best = probs[best_ind]\n",
    "    inds = np.argsort(best)[::-1]\n",
    "    probs = np.array(probs)\n",
    "    stats += ' 1st=%s(%.2f) 2nd=%s(%.2f) 3rd=%s(%.2f) components: >=0.5:%.0f, >=0.3:%.0f, >=0.1:%.0f'%(ind2name[inds[0]], best[inds[0]], ind2name[inds[1]], best[inds[1]], ind2name[inds[2]], best[inds[2]], np.sum(probs >= 0.5)/pop_size,np.sum(probs >= 0.3)/pop_size,np.sum(probs >= 0.1)/pop_size)\n",
    "  print(stats)\n",
    "  print('Best index: %s' % best_ind)\n",
    "  # save best vectors\n",
    "  save_vec(noise_vector[best_ind], outpath+'noise_%05d.txt'%sample_num) # saves the first vectors\n",
    "  save_vec(class_vector[best_ind], outpath+'class_%05d.txt'%sample_num)  \n",
    "  # save all vectors\n",
    "#   save_vec(noise_vector, outpath+'all_noise_%05d.txt'%sample_num) # saves the first vectors\n",
    "#   save_vec(class_vector, outpath+'all_class_%05d.txt'%sample_num)  \n",
    "  sample_num += 1\n",
    "\n",
    "def get_output(noise_vector, class_vector):\n",
    "  if stochastic_truncation:\n",
    "    with torch.no_grad():\n",
    "      trunc_indices = noise_vector.abs() > 2*truncation\n",
    "      size = torch.count_nonzero(trunc_indices).cpu().numpy()\n",
    "      trunc = truncnorm.rvs(-2*truncation, 2*truncation, size=(1,size)).astype(np.float32)\n",
    "      noise_vector.data[trunc_indices] = torch.tensor(trunc, requires_grad='SGD' in optimizer or 'Adam' in optimizer, device='cuda')\n",
    "  else:\n",
    "    noise_vector = noise_vector.clamp(-2*truncation, 2*truncation)\n",
    "  \n",
    "  if initial_class.lower() == 'random embeddings':\n",
    "    class_vector_norm = class_vector*emb_factor\n",
    "  else:\n",
    "    class_vector_norm = class_vector.softmax(dim=-1)\n",
    "  \n",
    "  return biggan_model(noise_vector, class_vector_norm, truncation), class_vector_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN Generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define forward pass\n",
    "def my_forward(self, z, class_label, truncation):\n",
    "  assert 0 < truncation <= 1\n",
    "\n",
    "  if initial_class.lower()=='random embeddings':\n",
    "    embed = class_label\n",
    "  else:\n",
    "    embed = self.embeddings(class_label)\n",
    "    \n",
    "#   print(z, embed, truncation)\n",
    "  cond_vector = torch.cat((z, embed), dim=1)\n",
    "\n",
    "  z = self.generator(cond_vector, truncation)\n",
    "  return z\n",
    "\n",
    "# set forward pass\n",
    "if gen_model == 'biggan':\n",
    "    BigGAN.forward = my_forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ascend_txt(i, grad_step=False, show_save=False):\n",
    "  prev_class_vector_norms = []\n",
    "  regs = []\n",
    "  losses = []\n",
    "  total_losses = []\n",
    "  best_loss = np.inf\n",
    "\n",
    "  # with CMA-ES we are creating a population of outputs\n",
    "  for j in range(pop_size):\n",
    "    p_s = []\n",
    "    \n",
    "    # not doing sigmoid now\n",
    "    if 'sigmoid' in gen_model:\n",
    "      out = noise_vector[j:j+1].sigmoid().reshape(1, channels, sideY, sideX)\n",
    "      prev_class_vector_norms = None\n",
    "    else:\n",
    "      out, class_vector_norm = get_output(noise_vector[j:j+1], class_vector[j:j+1])\n",
    "      if channels==1:\n",
    "        out = out.mean(dim=1, keepdim=True)\n",
    "      if initial_class.lower() == 'random embeddings':\n",
    "        prev_class_vector_norms = None\n",
    "      else:\n",
    "        with torch.no_grad():\n",
    "          prev_class_vector_norms.append(class_vector_norm.cpu().numpy()[0])\n",
    "    \n",
    "    # grayscale conversion\n",
    "    if channels==1:\n",
    "      out = out.repeat(1,3,1,1)\n",
    "    \n",
    "    # augmentations\n",
    "    for aug in range(augmentations):\n",
    "      if sideX<=clip_res and sideY<=clip_res:\n",
    "        apper = out  \n",
    "      else:\n",
    "        size = torch.randint(int(.5*sideX), int(.98*sideX), ())\n",
    "        #size = int(sideX*torch.zeros(1,).normal_(mean=.8, std=.3).clip(.5, .95))\n",
    "        offsetx = torch.randint(0, sideX - size, ())\n",
    "        offsety = torch.randint(0, sideX - size, ())\n",
    "        apper = out[:, :, offsetx:offsetx + size, offsety:offsety + size]\n",
    "        apper = (apper+1)/2\n",
    "      apper = torch.nn.functional.interpolate(apper, clip_res, mode='bicubic')\n",
    "      apper = apper.clamp(0,1)\n",
    "      p_s.append(apper)\n",
    "    \n",
    "    into = nom(torch.cat(p_s, 0))\n",
    "    predict_clip = perceptor.encode_image(into)\n",
    "    factor = 100\n",
    "    loss = factor*(1-torch.cosine_similarity(predict_clip, target_clip).mean())\n",
    "    total_loss = loss\n",
    "    \n",
    "    if 'sigmoid' in gen_model and total_variation_loss or 'biggan' in gen_model and (standartization_loss or optimize_class and (initial_class.lower() != 'random embeddings' and minimum_entropy_loss or  initial_class.lower() == 'random embeddings' and embeddings_l2_loss)):\n",
    "      reg = 0\n",
    "      if 'sigmoid' in gen_model:\n",
    "        if total_variation_loss:\n",
    "          reg += total_variation_loss*((out[:, :, :-1, :] - out[:, :, 1:, :]).abs().mean() + (out[:, :, :, :-1] - out[:, :, :, 1:]).abs().mean())\n",
    "      elif 'biggan' in gen_model:\n",
    "        if minimum_entropy_loss and initial_class.lower() != 'random embeddings':\n",
    "          reg += minimum_entropy_loss*((-class_vector_norm*torch.log(class_vector_norm+eps)).sum()-smoothed_ent).abs()\n",
    "        elif embeddings_l2_loss and initial_class.lower() == 'random embeddings':\n",
    "          reg += embeddings_l2_loss*class_vector_norm.square().sum()\n",
    "        if standartization_loss: #https://arxiv.org/abs/1903.00925\n",
    "          mu2 = noise_vector[j:j+1].mean().square()\n",
    "          sigma2 = noise_vector[j:j+1].std().square()\n",
    "          reg += standartization_loss*(mu2+sigma2-torch.log(sigma2))\n",
    "      reg = factor*reg\n",
    "      total_loss = total_loss + reg\n",
    "      with torch.no_grad():\n",
    "        regs.append(reg.item())\n",
    "    else:\n",
    "      regs.append(0)\n",
    "    \n",
    "    # store losses\n",
    "    with torch.no_grad():\n",
    "      losses.append(loss.item())\n",
    "      total_losses.append(total_loss.item())\n",
    "        \n",
    "    if total_losses[-1]<best_loss:\n",
    "      best_loss = total_losses[-1]\n",
    "      best_ind = j\n",
    "      best_out = out\n",
    "    \n",
    "    if grad_step:    \n",
    "      optim.zero_grad()\n",
    "      total_loss.backward()\n",
    "      optim.step()\n",
    "      \n",
    "  if show_save and (i == iterations-1 or i % save_every == 0):\n",
    "    if i==iterations-1:\n",
    "      prompt_safe = prompt.replace(\" \",\"_\")\n",
    "      results_timestamp = resultspath+'%s_%s' % (prompt_safe, datetime.datetime.now().strftime('%Y%m%d_%H%M%S'))\n",
    "      save(best_out, results_timestamp+'.jpg')\n",
    "      save_vec(noise_vector[best_ind], results_timestamp+'_noise.txt')\n",
    "      save_vec(class_vector[best_ind], results_timestamp+'_class.txt')\n",
    "    if i % save_every == 0:\n",
    "      checkin(i, best_ind, total_losses, losses, regs, best_out, prev_class_vector_norms)  \n",
    "  return total_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setup output path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a fresh output directory\n",
    "outpath = \"/home/jovyan/work/output/\"\n",
    "resultspath = \"/home/jovyan/work/results/\"\n",
    "!rm -rf $outpath\n",
    "!mkdir -p $outpath\n",
    "!mkdir -p $resultspath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training setup:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main training loop: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample=7 iter=35 best: total=73.13 cos=73.12 reg=0.001 avg: total=75.04 cos=75.03 reg=0.006 std: total=1.08 cos=1.08 reg=0.003 1st=space_shuttle(0.55) 2nd=prison(0.28) 3rd=perfume(0.14) components: >=0.5:1, >=0.3:1, >=0.1:2\n",
      "Best index: 1\n",
      "took: 171 secs (4.76 sec/iter) on GPU 0: GeForce RTX 2080 Ti (UUID: GPU-fbb93c12-fae4-40d4-7476-fac1de670c57)\n",
      "took: 189 secs (4.75 sec/iter) on GPU 0: GeForce RTX 2080 Ti (UUID: GPU-fbb93c12-fae4-40d4-7476-fac1de670c57)\n"
     ]
    }
   ],
   "source": [
    "for prompt in prompts:\n",
    "\n",
    "    # seeding\n",
    "    if seed == 0:\n",
    "      seed = None\n",
    "\n",
    "    # torch.manual_seed(np.random.randint(sys.maxsize))\n",
    "    state = None if not seed else np.random.RandomState(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # initialization\n",
    "    eps = 1e-8\n",
    "    if 'sigmoid' in gen_model:\n",
    "      noise_size = channels*sideY*sideX\n",
    "      noise_vector = np.random.rand(pop_size, noise_size).astype(np.float32)\n",
    "      noise_vector = np.log((noise_vector+eps)/(1-noise_vector+eps))\n",
    "    else:\n",
    "      noise_vector = truncnorm.rvs(-2*truncation, 2*truncation, size=(pop_size, noise_size), random_state=state).astype(np.float32) #see https://github.com/tensorflow/hub/issues/214\n",
    "\n",
    "      if initial_class.lower() == 'random class':\n",
    "        class_vector = np.ones(shape=(pop_size, class_size), dtype=np.float32)*class_smoothing/999\n",
    "        class_vector[0,np.random.randint(class_size)] = 1-class_smoothing\n",
    "      elif initial_class.lower() == 'random dirichlet':\n",
    "        class_vector = dirichlet.rvs([pop_size/class_size] * class_size, size=1, random_state=state).astype(np.float32)\n",
    "      elif initial_class.lower() == 'random mix':\n",
    "        class_vector = np.random.rand(pop_size, class_size).astype(np.float32)\n",
    "      elif initial_class.lower() == 'random embeddings':\n",
    "        class_vector = np.random.randn(pop_size, class_size).astype(np.float32)\n",
    "      else:\n",
    "        if initial_class.lower() == 'from prompt':\n",
    "          initial_class = prompt\n",
    "        try:\n",
    "          class_vector = None\n",
    "          class_vector = one_hot_from_names(initial_class, batch_size=pop_size)\n",
    "          assert class_vector is not None\n",
    "          class_vector = class_vector*(1-class_smoothing*class_size/(class_size-1))+class_smoothing/(class_size-1)\n",
    "        except Exception as e:  \n",
    "          print('Error: could not find initial_class. Try something else.')\n",
    "          raise e\n",
    "\n",
    "      if initial_class.lower() != 'random embeddings':\n",
    "        class_vector = class_vector/np.sum(class_vector,axis=-1, keepdims=True)\n",
    "        class_vector = np.log(class_vector+eps)\n",
    "      initial_class_vector = class_vector[0]\n",
    "      if initial_class.lower() == 'random mix':\n",
    "        initial_class_vector = initial_class_vector*0-np.log(class_size)\n",
    "      if initial_class.lower() == 'random embeddings':\n",
    "        initial_class_vector = initial_class_vector*0\n",
    "      class_vector = torch.tensor(class_vector, requires_grad='SGD' in optimizer or 'Adam' in optimizer, device='cuda')\n",
    "      smoothed_ent = -torch.tensor(class_smoothing*np.log(class_smoothing/999+eps)+(1-class_smoothing)*np.log(1-class_smoothing+eps), dtype=torch.float32).cuda()\n",
    "    noise_vector = torch.tensor(noise_vector, requires_grad='SGD' in optimizer or 'Adam' in optimizer, device='cuda')\n",
    "\n",
    "    if 'SGD' in optimizer or 'Adam' in optimizer:\n",
    "      params = [noise_vector]\n",
    "      if optimize_class:\n",
    "        params = params + [class_vector]\n",
    "      if 'SGD' in optimizer:\n",
    "        optim = torch.optim.SGD(params, lr=learning_rate, momentum=0.9)  \n",
    "      else:\n",
    "        optim = torch.optim.Adam(params, lr=learning_rate)\n",
    "\n",
    "    tx = clip.tokenize(prompt)\n",
    "    with torch.no_grad():\n",
    "      target_clip = perceptor.encode_text(tx.cuda())\n",
    "\n",
    "    nom = torchvision.transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
    "    if 'CMA' in optimizer:\n",
    "      initial_vector = np.zeros(noise_size)\n",
    "      bounds = None\n",
    "      #if 'sigmoid' not in gen_model and not stochastic_truncation:\n",
    "      #  bounds = [-2*truncation*np.ones(noise_size),2*truncation*np.ones(noise_size)]\n",
    "      if optimize_class:\n",
    "        initial_vector = np.hstack([initial_vector, initial_class_vector])\n",
    "        #if not stochastic_truncation:\n",
    "        #  bounds[0] = list(bounds[0]) + [None]*class_size\n",
    "        #  bounds[1] = list(bounds[1]) + [None]*class_size\n",
    "      cma_opts = {'popsize': pop_size, 'seed': np.nan, 'AdaptSigma': True, 'CMA_diagonal': True, 'CMA_active': False, 'CMA_elitist':False, 'bounds':bounds}\n",
    "      cmaes = cma.CMAEvolutionStrategy(initial_vector, 1, inopts=cma_opts)\n",
    "\n",
    "    # training\n",
    "    sample_num = 0\n",
    "    machine = !nvidia-smi -L\n",
    "    start = time()\n",
    "\n",
    "    for i in range(iterations):    \n",
    "      if 'CMA' in optimizer:\n",
    "        with torch.no_grad():\n",
    "          cma_results = torch.tensor(cmaes.ask(), dtype=torch.float32).cuda()\n",
    "          if optimize_class:\n",
    "            noise_vector.data, class_vector.data = torch.split_with_sizes(cma_results, (noise_size, class_size), dim=-1)\n",
    "            class_vector.data = class_vector.data\n",
    "          else:\n",
    "            noise_vector.data = cma_results      \n",
    "      if 'SGD' in optimizer or 'Adam' in optimizer:\n",
    "        losses = ascend_txt(i, grad_step=True, show_save='CMA' not in optimizer)\n",
    "        assert noise_vector.requires_grad and noise_vector.is_leaf and (not optimize_class or class_vector.requires_grad and class_vector.is_leaf), (noise_vector.requires_grad, noise_vector.is_leaf, class_vector.requires_grad, class_vector.is_leaf)\n",
    "      if 'CMA' in optimizer:\n",
    "        with torch.no_grad():\n",
    "          losses = ascend_txt(i, show_save=True)\n",
    "          if optimize_class:\n",
    "            vectors = torch.cat([noise_vector,class_vector], dim=1)\n",
    "          else:\n",
    "            vectors = noise_vector\n",
    "          cmaes.tell(vectors.cpu().numpy(), losses)\n",
    "      if i == iterations-1 or i % save_every == 0:\n",
    "        print('took: %d secs (%.2f sec/iter) on %s'%(time()-start,(time()-start)/(i+1), machine[0]))\n",
    "\n",
    "    newdir = outpath[:-1]+\"_\"+datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    !mv $outpath $newdir\n",
    "    !mkdir -p $outpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Based on SIREN+CLIP Colabs by: [@advadnoun](https://twitter.com/advadnoun), [@norod78](https://twitter.com/norod78)\n",
    "\n",
    "Other CLIP notebooks: [OpenAI tutorial](https://colab.research.google.com/github/openai/clip/blob/master/Interacting_with_CLIP.ipynb), [SIREN by @advadnoun](https://colab.research.google.com/drive/1FoHdqoqKntliaQKnMoNs3yn5EALqWtvP), [SIREN by @norod78](https://colab.research.google.com/drive/1K1vfpTEvAmxW2rnhAaALRVyis8EiLOnD), [BigGAN by @advadnoun](https://colab.research.google.com/drive/1NCceX2mbiKOSlAd_o7IU7nA9UskKN5WR), [BigGAN by @eyaler](j.mp/bigclip), [BigGAN by @tg_bomze](https://colab.research.google.com/github/tg-bomze/collection-of-notebooks/blob/master/Text2Image_v2.ipynb), [BigGAN using big-sleep library by @lucidrains](https://colab.research.google.com/drive/1MEWKbm-driRNF8PrU7ogS5o3se-ePyPb), [BigGAN story hallucinator by @bonkerfield](https://colab.research.google.com/drive/1jF8pyZ7uaNYbk9ZiVdxTOajkp8kbmkLK), [StyleGAN2-ADA Anime by @nagolinc](https://colab.research.google.com/github/nagolinc/notebooks/blob/main/TADNE_and_CLIP.ipynb) [v2](https://colab.research.google.com/github/nagolinc/notebooks/blob/main/CLIP_%2B_TADNE_(pytorch)_v2.ipynb)\n",
    "\n",
    "Using the works:\n",
    "\n",
    "https://github.com/openai/CLIP\n",
    "\n",
    "https://tfhub.dev/deepmind/biggan-deep-512\n",
    "\n",
    "https://github.com/huggingface/pytorch-pretrained-BigGAN\n",
    "\n",
    "http://www.aiartonline.com/design-2019/eyal-gruss (WanderGAN)\n",
    "\n",
    "For a curated list of more online generative tools see: [j.mp/generativetools](https://j.mp/generativetools)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leftovers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ~0. One-Time Setup~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(UPDATE: all of this has been moved to the docker image on gitlab 2021-02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cellView": "form",
    "id": "EWmKTmvBg7z5"
   },
   "outputs": [],
   "source": [
    "# !nvidia-smi -L\n",
    "\n",
    "# import subprocess\n",
    "\n",
    "# CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n",
    "# print(\"CUDA version:\", CUDA_version)\n",
    "\n",
    "# if CUDA_version == \"10.0\":\n",
    "#     torch_version_suffix = \"+cu101\"\n",
    "# #     torch_version_suffix = \"+cu100\"\n",
    "# elif CUDA_version == \"10.1\":\n",
    "#     torch_version_suffix = \"+cu101\"\n",
    "# elif CUDA_version == \"10.2\":\n",
    "#     torch_version_suffix = \"\"\n",
    "# else:\n",
    "#     torch_version_suffix = \"+cu110\"\n",
    "\n",
    "# !pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html ftfy regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cellView": "form",
    "id": "1SDpkkK7cU1y",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install pytorch-pretrained-biggan\n",
    "# !pip install nltk\n",
    "# !pip install cma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo apt-get install -y ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install code repo for CLIP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone --depth 1 https://github.com/openai/CLIP"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "WanderCLIP.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
